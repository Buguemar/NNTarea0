{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 0 - Introducción a Redes Neuronales </H3>\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<p align='center'> Alfredo Silva Celpa   201373511-8 </p>\n",
    "<p align='center'> Margarita Bugueño Pérez   201373510-K </p>\n",
    "\n",
    "**Temas**  \n",
    "* NNs por dentro: *back-propagation from scratch*.\n",
    "* Principales hiperparámetros de *back propagation*\n",
    "* Introducción a keras\n",
    "* Verificación numérica de las derivadas implementadas.\n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de responder preguntas sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega: 30 de Marzo.\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea0-INF395-I-2018]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "\n",
    "#### Paquetes instalación\n",
    "Para poder trabajar en el curso se necesitará instalar librerías para Python, por lo que se recomienda instalarlas a través de *anaconda* (para Windows y sistemas Unix) en un entorno virtual, donde podrán elegir su versión de Python. Se instalarán librerías como __[*sklearn*](http://scikit-learn.org/stable/)__, una librería simple y de facil acceso para *data science*, __[*keras*](https://keras.io/)__ en su versión con GPU (para cálculo acelerado a través de la tarjeta gráfica), además de que ésta utiliza como *backend* *TensorFlow* o *Theano*, por lo que habrá que instalar alguno de éstos, además de las librerías básicas de *computer science* como *numpy*, *matplotlib*, *pandas*, además de claramente *jupyter*.\n",
    "\n",
    "* __[Descargar anacona](https://www.anaconda.com/download/#linux)__ \n",
    "\n",
    "* Luego de instalar Anaconda y tenerla en el *path* de su computador crear un entorno virtual: \n",
    "```\n",
    "conda create -n redesneuronales python=version\n",
    "```\n",
    "\n",
    "con *version*, la version de Python que desea utilizar. Si está en Windows, se recomienda Python 3 debido a dependencias con una de las librerías a utilziar.\n",
    " \n",
    "* Acceder al ambiente creado \n",
    "```\n",
    "source activate redesneuronales\n",
    "```\n",
    "\n",
    "* Instalar los paquetes a utilizar\n",
    "```\n",
    "conda install jupyter sklearn numpy pandas matplotlib keras-gpu tensorflow-gpu \n",
    "```\n",
    "\n",
    "* Para salir del entorno\n",
    "```\n",
    "source deactivate redesneuronales\n",
    "```\n",
    "<hr style=\"height:1px;border:none\"/>\n",
    "\n",
    "\n",
    "La tarea se divide en cuatro secciones:\n",
    "\n",
    "[1.](#primero)   Back-propagation (BP) from *Scratch*   \n",
    "[2.](#segundo)   Comparar back-propagation (BP) de Keras  \n",
    "[3.](#tercero)   Verificación numérica del gradiente para una componente  \n",
    "[4.](#cuarto)   Implementar momentum como variante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Back-propagation (BP) from *Scratch*\n",
    "\n",
    "BP (Back-propagation) es sin duda el paradigma dominante para entrenar redes neuronales *feed-forward*. En\n",
    "redes grandes, diseñadas para problemas reales, implementar BP eficientemente puede ser una tarea delicada\n",
    "que puede ser razonable delegar a una librerı́a especializada. Sin embargo, construir BP *from scratch* es muy\n",
    "útil con fines pedagógicos.\n",
    "\n",
    "$$ w^{(t+1)} \\leftarrow w^{(t)} - \\eta \\nabla_{w^{(t)}} Loss $$\n",
    " \n",
    "> a) Escriba un programa que permita entrenar una red FF con una arquitectura fija de 2 capa ocultas (con 32 neuronas en la primera capa y 16 en la segunda) y $K$ neuronas de salida, sin usar librerı́as, excepto eventualmente *numpy* para implementar operaciones básicas de algebra lineal. Por simplicidad, asuma funciones de activacion y error (*loss function*) diferenciables o subdiferenciables, además de tener la misma función de activación para las 2 capas ocultas. Adapte la arquitectura para un problema de clasificación de 3 clases, es decir la función de activación para la capa de salida debe ser **softmax** con número de neuronas $K$=3. Escriba funciones para:  \n",
    "* (i)  implementar el *forward pass*  \n",
    "* (ii) implementar el *backward pass*  \n",
    "* (iii) implementar la rutina principal de entrenamiento, adoptando, por simplicidad, la variante cíclica aleatorizada de SGD (un ejemplo a la vez, pero iterando cíclicamente sobre una configuración aleatoria del conjunto de entrenamiento) con una tasa de aprendizaje fija de 0.1 y número de ciclos fijos (*epochs*).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Inicializar en algún modo;\n",
    "#while criterio de parada insatisfecho do\n",
    "#for Cada ejemplo (xi, yi ) do\n",
    "#  Forward pass (xi, yi );\n",
    "#  Medir error E = E(xi, yi );\n",
    "#  Backward pass E;\n",
    "\n",
    "#se debe entrenar por batches. Tal que, se pasan en forwarding un batch completo (cada ejemplo permite computar \n",
    "# el error, se almacen en un arreglo (?) y se procede con el backwarding que sólo se ejecutará para obtener el \n",
    "# gradiente de cada error y almacenarlo en un arreglo nuevamente para, al final del batch realizar el backprop \n",
    "# con actualizacion de pesos)\n",
    "# nuevamente realizar este procedimiento con el siguiente batch de entrenamiento y fin :D\n",
    "epsilon=1e-15\n",
    "def sigmoidal(x):\n",
    "    if (x>0):\n",
    "        x = np.maximum(epsilon,x)\n",
    "        return 1/(1+ np.exp(-x))\n",
    "    elif(x<0):\n",
    "        x = np.maximum(-600,x)\n",
    "        return 1/(1+ np.exp(-x))\n",
    "    else:\n",
    "        return 1/(1+ np.exp(-(epsilon)))\n",
    "\n",
    "def d_sigmoidal(x):\n",
    "    return sigmoidal(x)*(1-sigmoidal(x))\n",
    "\n",
    "#donde x es un vector\n",
    "def softmax(x):\n",
    "    salida=[] \n",
    "    suma=0.0\n",
    "    for elemento in range(len(x)):\n",
    "        suma+=np.exp(x[elemento])\n",
    "    #print (suma)\n",
    "    for elemento in range(len(x)):\n",
    "        temp=np.exp(x[elemento])/suma\n",
    "        salida.append(temp)\n",
    "    #print (salida)\n",
    "    return salida\n",
    "\n",
    "def d_softmax(x):\n",
    "    return softmax(x)*(np.subtract(1,softmax(x)))\n",
    "\n",
    "def error_mse(ytrue, ypred):\n",
    "    # no se si debamos imlementarlo como 1/2*(ytrue-ypred)**2\n",
    "    return (0.5)*((np.subtract(ytrue,ypred))**2)\n",
    "\n",
    "def d_error_mse(ytrue, ypred):\n",
    "    # si es asi, entonces se omitiría el 2 aquí\n",
    "    return (np.subtract(ytrue,ypred))\n",
    "\n",
    "#ypred, ytrue componentes\n",
    "def error_CE(ytrue,ypred):\n",
    "    #return ((ytrue*ypred)+(1-ytrue)*(1-ypred))\n",
    "    vector_retorno=[]\n",
    "    for i in range(len(ytrue)):\n",
    "        ypred[i] = np.maximum(ypred[i],epsilon)\n",
    "        #resta = np.maximum(1-ypred[i],epsilon) \n",
    "        temp=-(ytrue[i]*np.log(ypred[i]))#-(1-ytrue[i])*(np.log(resta))\n",
    "        vector_retorno.append(temp)\n",
    "    return vector_retorno\n",
    "\n",
    "def d_error_CE(ytrue,ypred):\n",
    "    #return (np.subtract(ytrue,ypred))/(ypred*(np.subtract(1,ypred)))\n",
    "    vector_retorno=[]\n",
    "    for i in range(len(ytrue)):\n",
    "        \"\"\"\n",
    "        ypred[i] = np.maximum(ypred[i],epsilon)\n",
    "        resta = np.maximum(1-ypred[i],epsilon)\n",
    "        temp=(ytrue[i]-ypred[i])/(ypred[i]*(resta))\n",
    "        if temp==np.inf:\n",
    "            vector_retorno.append(300)\n",
    "        elif temp==-(np.inf):\n",
    "            vector_retorno.append(-300)\n",
    "        else:\n",
    "        \"\"\"\n",
    "        ypred[i] = np.maximum(ypred[i],epsilon)\n",
    "        temp = -ytrue[i]/ypred[i]\n",
    "        vector_retorno.append(temp)\n",
    "    return vector_retorno\n",
    "\n",
    "\n",
    "#definir el modelo y su arquitectura\n",
    "#total capas= capas ocultas + capa de salida\n",
    "def size_layers(total_capas,input_size,n_capa_o1, n_capa_o2, n_capa_out):\n",
    "    sizes=np.arange(total_capas+1)\n",
    "    sizes[0]=input_size\n",
    "    sizes[1]=n_capa_o1\n",
    "    sizes[2]=n_capa_o2    \n",
    "    sizes[3]=n_capa_out\n",
    "    return sizes\n",
    "\n",
    "def iniciar_estructuras(total_capas,tamanios_arquit):\n",
    "    #vector sallida de cada capa, vector derivada de sallida respecto a w, vector error en la salida de cada capa\n",
    "    salida_l=[]\n",
    "    da_salida_l=[]\n",
    "    e_salida_l=[]\n",
    "    for i in np.arange(total_capas+1):        \n",
    "        if i<total_capas:\n",
    "            salida_l.append(np.zeros(tamanios_arquit[i+1]))\n",
    "            #print (i)\n",
    "            #print (np.zeros(tamanios_arquit[i+1]))\n",
    "        else: \n",
    "            salida_l.append(np.zeros(tamanios_arquit[0]))\n",
    "            #print (salida_l[-1])\n",
    "            \n",
    "    da_salida_l=salida_l.copy()\n",
    "    e_salida_l=salida_l.copy()    \n",
    "    #matrices de pesos originales, matrices errores de pesos\n",
    "    #matrices de peso inicializadas como 1\n",
    "    m_pesos=[]\n",
    "    for i in np.arange(total_capas):\n",
    "        #print (np.ones((tamanios_arquit[i],tamanios_arquit[i+1])))\n",
    "        m_pesos.append(np.random.random([tamanios_arquit[i],tamanios_arquit[i+1]]))\n",
    "    #m_pesos.append(m_pesos_c1_c2)\n",
    "    #m_pesos.append(m_pesos_c2_c3)\n",
    "    #matrices de errores en los pesos inicializadas como 0\n",
    "    e_m_pesos=[]\n",
    "    for i in np.arange(total_capas):\n",
    "        #print (np.zeros((tamanios_arquit[i],tamanios_arquit[i+1])))\n",
    "        e_m_pesos.append(np.zeros((tamanios_arquit[i],tamanios_arquit[i+1])))  \n",
    "      \n",
    "    return salida_l, da_salida_l, e_salida_l, m_pesos, e_m_pesos    \n",
    "\n",
    "def one_hot(posicion):\n",
    "    array=np.zeros(3)\n",
    "    array[posicion]=1\n",
    "    return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwarding(total_capas, vector_x, salida_l, da_salida_l,m_pesos, vector_arquit):\n",
    "    vector=vector_x.copy() #se modifica en cada capa\n",
    "    salida_l[-1]=vector.copy()\n",
    "    ##################333333######DERIVADAAAA\n",
    "    da_salida_l[-1]=vector.copy()\n",
    "    ##################### DERIVADA\n",
    "    for capa in range(total_capas-1):\n",
    "        salida_capa=[]\n",
    "        d_salida_capa=[]\n",
    "        for neurona in range(vector_arquit[capa+1]):\n",
    "            #pesos como vector columna de m_pesos\n",
    "            w=(m_pesos[capa].T[neurona]).copy() #vector pesos hacia neurona desde las xs inputs (vector dimesion entrada a capa)\n",
    "            #print (\"es w\",w)\n",
    "            temp= np.dot(vector,w)\n",
    "            #if type(temp)==:\n",
    "            #print (\"es temp\",temp)\n",
    "            temp=sigmoidal(temp)\n",
    "            temp2=d_sigmoidal(temp)\n",
    "            salida_capa.append(temp)\n",
    "            d_salida_capa.append(temp2)\n",
    "        salida_l[capa]=salida_capa.copy()\n",
    "        da_salida_l[capa]=d_salida_capa.copy()\n",
    "        vector=salida_capa.copy()\n",
    "        #print (\"VECTOR SALIDA CAPA ES\",vector)\n",
    "    salida_last_t=[]\n",
    "    d_salida_last=[] \n",
    "    for neurona in range(vector_arquit[-1]): #0,1,2               \n",
    "        #pesos como vector columna de m_pesos\n",
    "        w=(m_pesos[-1].T[neurona]).copy() #vector pesos entre ult. capa oculta y la capa out (dimesion largo de capa anterior)\n",
    "        temp= np.dot(vector,w) #elemento i-esimo entrada a softmax (de la salida de la capa)\n",
    "        salida_last_t.append(temp) #vector de w*a    \n",
    "    salida_last=softmax(salida_last_t)\n",
    "    d_salida_last=d_softmax(salida_last_t)\n",
    "    salida_l[-2]=salida_last.copy()\n",
    "    da_salida_l[-2]=d_salida_last.copy()\n",
    "    vector=salida_last.copy()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwarding(total_capas, vector_x, vector_y, tipo_error ,tasa, salida_l, da_salida_l,e_salida_l,m_pesos, vector_arquit):\n",
    "        if tipo_error==\"mse\":\n",
    "            error_EA=d_error_mse(vector_y,salida_l[-2])\n",
    "        else:\n",
    "            error_EA=d_error_CE(vector_y,salida_l[-2])            \n",
    "        for neurona_final in range(vector_arquit[-1]):\n",
    "            error_EW_n=error_EA[neurona_final]*da_salida_l[-2][neurona_final]*np.array(salida_l[-3])\n",
    "            #correccion vector de pesos-matriz final correspondiente a la neurona\n",
    "            pesos_auxiliar=m_pesos[total_capas-1].T.copy()\n",
    "            pesos_auxiliar[neurona_final]= pesos_auxiliar[neurona_final]-(tasa*error_EW_n)\n",
    "            m_pesos[total_capas-1]=pesos_auxiliar.T.copy()\n",
    "        #print (\"--------------------------------------------\")\n",
    "        #print (\"M PESOS FINAL LISTO\", m_pesos[total_capas-1])\n",
    "        e_salida_l[total_capas-1]=error_EA.copy() #es el triangulo (Delta mayus.)        \n",
    "        #backwarding de capas ocultas y capa input\n",
    "        #corrección de pesos que debiese ser por batch         \n",
    "        for capa in np.arange(total_capas-2,-1,-1): #se mueve en capa 1 y 0\n",
    "            #print (\"e_salida siguiente capa\",e_salida_l[capa+1])\n",
    "            error_EA_s=np.sum(e_salida_l[capa+1]) #suma el vector EA calculado en la capa 2 (igual para todos)\n",
    "            error_aux=[]\n",
    "            pesos_auxiliar2=m_pesos[capa].T.copy() #se hace (16x32 la matriz)\n",
    "            for neurona in range(vector_arquit[capa+1]):\n",
    "                #print (\"NEURONA\", neurona)\n",
    "                error_EW_s=error_EA_s*da_salida_l[capa][neurona]*np.array(salida_l[capa-1])\n",
    "                #corregir pesos\n",
    "                #pesos_auxiliar2=m_pesos[capa].T #se hace (16x32 la matriz)\n",
    "                #print (\"NEURONA\", neurona)\n",
    "                #print (\"CAPA\", capa)\n",
    "                arreglo=(pesos_auxiliar2[neurona]-(tasa*error_EW_s)).copy() #(vector de 32)\n",
    "                pesos_auxiliar2[neurona]=arreglo.copy()  #se hace\n",
    "                #print (\"entonces megatemp\", arreglo)\n",
    "                #print (\"entonces pesos auxiliar\",pesos_auxiliar2[neurona])\n",
    "                #print (\"entonces pesos aux \",pesos_auxiliar2)\n",
    "                #print (\"pesos ANTES!!! \",m_pesos[capa])\n",
    "                m_pesos[capa]=(pesos_auxiliar2.T).copy()                \n",
    "                #print (\"pesos AHORA!!! \",m_pesos[capa])\n",
    "                #print (\"pesos debiesen ser ahora\", pesos_auxiliar2.T)\n",
    "                #print (\"pesos ahora\",m_pesos[capa])                \n",
    "                #print (\"M PESOS EN CAPA\", capa, \"ES \", m_pesos[capa], \"Pero DEBIESE SER\", np.array(auxiliar2).T)\n",
    "                error_aux.append(error_EA_s)\n",
    "            e_salida_l[capa]=error_aux.copy()\n",
    "            \n",
    "        return m_pesos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_2ocultas:\n",
    "    def __init__(self, total_capas, tamanios_arquit):\n",
    "        self.n_capa_in=tamanios_arquit[0]\n",
    "        self.n_capa_1=tamanios_arquit[1]\n",
    "        self.n_capa_2=tamanios_arquit[2]\n",
    "        self.n_capa_out=tamanios_arquit[3]\n",
    "        self.total_capas=total_capas\n",
    "        self.salidas_l, self.da_salida_l, self.e_salida_l, self.m_pesos, self.e_m_pesos=iniciar_estructuras(total_capas,tamanios_arquit)\n",
    "\n",
    "    def training(self, Xtrain, Ytrain, epoch, error):\n",
    "        #X_aux = Xtrain.copy()\n",
    "        #select = numpy.random.choice(Xtrain, size=epoch, replace=False)\n",
    "        #for xs in select:\n",
    "            t=size_layers(self.total_capas,self.n_capa_in,self.n_capa_1, self.n_capa_2, self.n_capa_out)\n",
    "            y_pred=forwarding(self.total_capas, Xtrain, self.salidas_l, self.da_salida_l,self.m_pesos, t)\n",
    "            \n",
    "            if(error==\"mse\"):\n",
    "                v_e = error_mse(y_pred, Ytrain)\n",
    "            else:\n",
    "                print(\"ypred\",y_pred)\n",
    "                print(\"ytrain\",Ytrain)\n",
    "                v_e = error_CE(y_pred, Ytrain)\n",
    "                print (\"ERRORES CE VECOR\", v_e)\n",
    "                E = sum(v_e)/len(v_e)\n",
    "            \n",
    "            self.m_pesos = backwarding(self.total_capas, Xtrain, Ytrain, error ,0.1, self.salidas_l, self.da_salida_l,self.e_salida_l,self.m_pesos, t)\n",
    "            return E\n",
    "        #for x in Xtrain:\n",
    "        #  Forward pass (xi, yi );\n",
    "        #  Medir error E = E(xi, yi );\n",
    "        #ojo! backwarding-SGD por batch (este caso es batch tamaño 1)\n",
    "        #  Backward pass E;\n",
    "    def entrenamiento(self,Xtrain,Ytrain):\n",
    "        errores=[]\n",
    "        for j in range(X_train.shape[0]):\n",
    "            print(\"Epoch: \",j)\n",
    "            error=modelo.training(Xtrain[j],Ytrain[j],1,\"ce\")\n",
    "            print(\"Error del epoch: \",error)\n",
    "            errores.append(error)\n",
    "        return errores\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Escriba una función que permita hacer predicciones mediante la red FF definida anteriormente, sin usar librerı́as, excepto eventualmente *numpy*. Escriba una función vectorizada que implemente el forward pass sobre un conjunto de $n_{t}$ ejemplos, además de implementar la función de decisión, que a través de la salida de la red prediga el valor categórico de la clase (1, 2 o 3).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion(redN,df_x,df_y,vector_arquit):\n",
    "    vector_clase=[]\n",
    "    for ejemplo in range(df_x.shape[0]):\n",
    "        vector_x=df_x[ejemplo]\n",
    "        temp_retorno=forwarding(redN.total_capas, vector_x, redN.salidas_l, redN.da_salida_l,redN.m_pesos, vector_arquit)\n",
    "        vector_clase.append(temp_retorno)\n",
    "    return vector_clase\n",
    "\n",
    "def clase_vector(array_vector):\n",
    "    to_return=[]\n",
    "    for arreglo in array_vector:\n",
    "        aux=np.argmax(a)+1\n",
    "        to_return.append(aux)\n",
    "    return to_return\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Demuestre que sus programas funcionan en un problema de clasificación. Para esto utilice el dataset **iris**, disponible a través de la librería __[*sklearn*](http://scikit-learn.org)__, el cual corresponde a la clasificación de distintos tipos de plantas de iris (3 clases) mediante 4 características reales continuas específicas de la planta, deberá entrenar (ajustar) los pesos de la red para realizar la tarea encomendada, variando las funciones de error (*loss*) entre *categorical cross entropy* y *mean squared error*, además de variar las funciones de activación para las 2 capas ocultas entre  ReLU (Rectifier Linear Unit) y la función logística (*sigmoid*). Especifique explícitamente las funciones anteriores, así como sus gradientes. Recuerde que debe transformar las etiquetas usando *one hot vectors*.\n",
    "<div class=\"alert alert-block alert-info\">Es una buena práctica el normalizar los datos antes de trabajar con el modelo</div>\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "X_train,y_train = load_iris(return_X_y=True)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "#transform target to one hot vector\n",
    "import keras\n",
    "y_onehot = keras.utils.to_categorical(y_train)\n",
    "```\n",
    "Para evaluar los resultados, construya un gráfico correspondiente al error de clasificación versus número\n",
    "de epochs, utilizando sólo el conjunto de entrenamiento (el objetivo de esta sección es familiarizarse\n",
    "con el algoritmo BP, no encontrar la mejor red). Grafique también la evolución de la función objetivo utilizada para el entrenamiento. Además de reportar el tiempo de entrenamiento mediante el algoritmo implementado.  \n",
    "Por último, para alguna configuración elegida, reporte la matriz de confusión mediante el uso de librerías como *sklearn* o *keras*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "Epoch:  0\n",
      "ypred [0.54590602267533606, 0.17433814292510166, 0.27975583439956236]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 6.0214261355940666, 9.6624242094981465]\n",
      "Error del epoch:  5.22795011503\n",
      "Epoch:  1\n",
      "ypred [0.71234109443114224, 0.11034297112723172, 0.17731593444162599]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 3.8111112065135422, 6.1242754109339623]\n",
      "Error del epoch:  3.31179553915\n",
      "Epoch:  2\n",
      "ypred [0.79690139604566179, 0.077906598246955228, 0.12519200570738295]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 2.6907985765397271, 4.3239786915576817]\n",
      "Error del epoch:  2.33825908937\n",
      "Epoch:  3\n",
      "ypred [0.84448663695662274, 0.059653376363895082, 0.095859986679482187]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 2.0603546274340223, 3.310886645141752]\n",
      "Error del epoch:  1.79041375753\n",
      "Epoch:  4\n",
      "ypred [0.8744420573150109, 0.048162776143957704, 0.077395166541031499]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 1.6634833557942938, 2.67313435120756]\n",
      "Error del epoch:  1.44553923567\n",
      "Epoch:  5\n",
      "ypred [0.89489169701119586, 0.040318498247445808, 0.064789804741358384]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 1.392551595547129, 2.2377605786317014]\n",
      "Error del epoch:  1.21010405806\n",
      "Epoch:  6\n",
      "ypred [0.90969238588801704, 0.034641101474977912, 0.055666512637004964]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 1.1964612579176728, 1.9226532326539842]\n",
      "Error del epoch:  1.03970483019\n",
      "Epoch:  7\n",
      "ypred [0.92088093785159886, 0.030349284393449704, 0.048769777754951414]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 1.0482271474109119, 1.684448448707756]\n",
      "Error del epoch:  0.910891865373\n",
      "Epoch:  8\n",
      "ypred [0.92962658522936237, 0.026994541161295137, 0.043378873609342429]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.93235842105318534, 1.4982532158561703]\n",
      "Error del epoch:  0.81020387897\n",
      "Epoch:  9\n",
      "ypred [0.93664585321341787, 0.024302019863942381, 0.039052126922639707]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.83936203002538368, 1.3488126795267243]\n",
      "Error del epoch:  0.729391569851\n",
      "Epoch:  10\n",
      "ypred [0.94240131799483362, 0.022094280886467317, 0.035504401118698965]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.76310942714404373, 1.2262785712739603]\n",
      "Error del epoch:  0.663129332806\n",
      "Epoch:  11\n",
      "ypred [0.94720451813406559, 0.020251821141705498, 0.032543660724228859]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.69947312200309097, 1.1240182208259777]\n",
      "Error del epoch:  0.60783044761\n",
      "Epoch:  12\n",
      "ypred [0.95127274008983886, 0.01869129170879183, 0.03003596820136924]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.64557434486200904, 1.0374055895117398]\n",
      "Error del epoch:  0.560993311458\n",
      "Epoch:  13\n",
      "ypred [0.95476204975814483, 0.017352827264518922, 0.027885122977336314]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.59934542070872865, 0.96311802725880502]\n",
      "Error del epoch:  0.520821149323\n",
      "Epoch:  14\n",
      "ypred [0.95778737766946964, 0.01619234160201798, 0.02602028072851242]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.55926366590210885, 0.89870865781489417]\n",
      "Error del epoch:  0.485990774572\n",
      "Epoch:  15\n",
      "ypred [0.96043520153792183, 0.015176662731347062, 0.02438813573073105]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.52418336049897063, 0.84233636669245138]\n",
      "Error del epoch:  0.45550657573\n",
      "Epoch:  16\n",
      "ypred [0.96277181870024797, 0.014280359654322205, 0.02294782164542981]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.4932261489395387, 0.79258968056179158]\n",
      "Error del epoch:  0.4286052765\n",
      "Epoch:  17\n",
      "ypred [0.9648488963568731, 0.013483613347349545, 0.021667490295777348]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.46570750639953912, 0.748368602364751]\n",
      "Error del epoch:  0.404692036255\n",
      "Epoch:  18\n",
      "ypred [0.96670728866460987, 0.012770752562684104, 0.020521958772706017]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.44108616715727883, 0.7088033452360688]\n",
      "Error del epoch:  0.383296504131\n",
      "Epoch:  19\n",
      "ypred [0.96837971990572624, 0.012129224591498794, 0.019491055502775082]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.41892857600942873, 0.673197207711142]\n",
      "Error del epoch:  0.364041927907\n",
      "Epoch:  20\n",
      "ypred [0.96989270764208313, 0.011548857561109595, 0.018558434796807268]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.39888340891983787, 0.64098562968645589]\n",
      "Error del epoch:  0.346623012869\n",
      "Epoch:  21\n",
      "ypred [0.97126796536581639, 0.011021322392142414, 0.017710712242041203]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.38066298967842899, 0.61170632992246843]\n",
      "Error del epoch:  0.3307897732\n",
      "Epoch:  22\n",
      "ypred [0.97252344170989646, 0.010539734167710273, 0.016936824122393238]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.36402952168034519, 0.58497718120326947]\n",
      "Error del epoch:  0.316335567628\n",
      "Epoch:  23\n",
      "ypred [0.97367410141297284, 0.010098352563075919, 0.016227546023951111]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.34878474113305236, 0.56047958355936933]\n",
      "Error del epoch:  0.303088108231\n",
      "Epoch:  24\n",
      "ypred [0.97473251985204168, 0.0096923537888407886, 0.015575126359117666]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.33476204025313738, 0.53794580664004443]\n",
      "Error del epoch:  0.290902615631\n",
      "Epoch:  25\n",
      "ypred [0.97570934102695117, 0.0093176549126484202, 0.014973004060400452]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.32182039955290481, 0.51714923920226097]\n",
      "Error del epoch:  0.279656546252\n",
      "Epoch:  26\n",
      "ypred [0.97661363420153324, 0.0089707770551984319, 0.014415588743268232]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.309839662798094, 0.49789679620473298]\n",
      "Error del epoch:  0.269245486334\n",
      "Epoch:  27\n",
      "ypred [0.97745317441019353, 0.0086487377907113437, 0.01389808779909522]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.29871682065159294, 0.48002294680978619]\n",
      "Error del epoch:  0.259579922487\n",
      "Epoch:  28\n",
      "ypred [0.97823466512401169, 0.0083489657344292794, 0.013416369141559045]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.28836306063022416, 0.46338497381188765]\n",
      "Error del epoch:  0.250582678147\n",
      "Epoch:  29\n",
      "ypred [0.97896391651716397, 0.0080692321613920308, 0.012966851321444125]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.27870140530094117, 0.44785917833741073]\n",
      "Error del epoch:  0.242186861213\n",
      "Epoch:  30\n",
      "ypred [0.97964598932221536, 0.0078075958249787854, 0.012546414852805859]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.2696648063807805, 0.43333781715884784]\n",
      "Error del epoch:  0.234334207847\n",
      "Epoch:  31\n",
      "ypred [0.98028531177645195, 0.0075623580974600001, 0.012152330126088006]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.26119459534641309, 0.4197266129020904]\n",
      "Error del epoch:  0.226973736083\n",
      "Epoch:  32\n",
      "ypred [0.98088577534986621, 0.0073320262496951016, 0.011782198400438707]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.25323921515983466, 0.40694271599322684]\n",
      "Error del epoch:  0.220060643718\n",
      "Epoch:  33\n",
      "ypred [0.98145081361127162, 0.007115283198876215, 0.011433903189852036]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.2457531753924504, 0.39491302559535546]\n",
      "Error del epoch:  0.213555400329\n",
      "Epoch:  34\n",
      "ypred [0.98198346759653954, 0.0069109624339237239, 0.011105569969536615]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.23869618617891919, 0.38357279791586019]\n",
      "Error del epoch:  0.207422994698\n",
      "Epoch:  35\n",
      "ypred [0.98248644029765164, 0.0067180271140279213, 0.010795532588320332]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.2320324363063575, 0.37286448613196732]\n",
      "Error del epoch:  0.201632307479\n",
      "Epoch:  36\n",
      "ypred [0.98296214232663082, 0.0065355525524200308, 0.010502305120949143]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.22572998822522322, 0.36273676820358786]\n",
      "Error del epoch:  0.196155585476\n",
      "Epoch:  37\n",
      "ypred [0.98341273037706711, 0.0063627114629137204, 0.010224558160019215]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.21976026848291202, 0.35314372802566307]\n",
      "Error del epoch:  0.190967998836\n",
      "Epoch:  38\n",
      "ypred [0.98384013977386642, 0.0061987614741457172, 0.0099610987519879492]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.21409763648090585, 0.34404416244253566]\n",
      "Error del epoch:  0.186047266308\n",
      "Epoch:  39\n",
      "ypred [0.98424611214426805, 0.0060430345152488905, 0.0097108533404830812]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.2087190178689089, 0.33540099213071661]\n",
      "Error del epoch:  0.181373336667\n",
      "Epoch:  40\n",
      "ypred [0.98463221904199971, 0.0058949277538617928, 0.0094728532041385444]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.20360359155478555, 0.32718075863955443]\n",
      "Error del epoch:  0.176928116731\n",
      "Epoch:  41\n",
      "ypred [0.98499988219826473, 0.0057538958280514219, 0.0092462219736839484]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.19873252140467751, 0.31935319324677963]\n",
      "Error del epoch:  0.172695238217\n",
      "Epoch:  42\n",
      "ypred [0.9853503909481216, 0.005619444161727531, 0.0090301648901508005]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.19408872536559352, 0.3118908459500917]\n",
      "Error del epoch:  0.168659857105\n",
      "Epoch:  43\n",
      "ypred [0.98568491728122365, 0.0054911231913291197, 0.0088239595274471651]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.18965667606222483, 0.3047687650362394]\n",
      "Error del epoch:  0.164808480366\n",
      "Epoch:  44\n",
      "ypred [0.98600452888617141, 0.0053685233621402892, 0.0086269477516883533]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.18542222797581756, 0.29796421936614148]\n",
      "Error del epoch:  0.161128815781\n",
      "Epoch:  45\n",
      "ypred [0.98631020049359741, 0.0052512707771959948, 0.0084385287292066107]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.18137246716270131, 0.29145645688009691]\n",
      "Error del epoch:  0.157609641348\n",
      "Epoch:  46\n",
      "ypred [0.98660282377121733, 0.005139023401639113, 0.0082581528271434296]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.17749558015742661, 0.2852264939317064]\n",
      "Error del epoch:  0.154240691363\n",
      "Epoch:  47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypred [0.98688321598191964, 0.0050314677415634942, 0.0080853162765168098]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.17378073926406779, 0.27925693095674592]\n",
      "Error del epoch:  0.15101255674\n",
      "Epoch:  48\n",
      "ypred [0.98715212758153326, 0.0049283159295855838, 0.0079195564888811642]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.17021800189543287, 0.27353179071633049]\n",
      "Error del epoch:  0.147916597537\n",
      "Epoch:  49\n",
      "ypred [0.98741024890467644, 0.0048293031602196675, 0.0077604479351038669]\n",
      "ytrain [ 1.  0.  0.]\n",
      "ERRORES CE VECOR [-0.0, 0.16679822199406261, 0.26803637595489882]\n",
      "Error del epoch:  0.144944865983\n",
      "Epoch:  50\n",
      "ypred [0.86430513450188839, 0.059839283487384501, 0.07585558201072698]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [29.852041777533927, -0.0, 2.6199589853743084]\n",
      "Error del epoch:  10.8240002543\n",
      "Epoch:  51\n",
      "ypred [0.84132552817471273, 0.084838259199981059, 0.073836212625306347]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [29.058354292956533, -0.0, 2.550212437712537]\n",
      "Error del epoch:  10.5361889102\n",
      "Epoch:  52\n",
      "ypred [0.81090848637621049, 0.11792228375467559, 0.071169229869114017]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [28.007786887683412, -0.0, 2.4580981166473275]\n",
      "Error del epoch:  10.1552950014\n",
      "Epoch:  53\n",
      "ypred [0.7723733560934779, 0.15983943760950517, 0.067787206297016844]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [26.676830639499357, -0.0, 2.3412871607283461]\n",
      "Error del epoch:  9.67270593341\n",
      "Epoch:  54\n",
      "ypred [0.72602092248149064, 0.21025998526433168, 0.063719092254177739]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [25.075874299614988, -0.0, 2.2007794794537303]\n",
      "Error del epoch:  9.09221792636\n",
      "Epoch:  55\n",
      "ypred [0.6734221324562677, 0.26747586217179437, 0.059102005371938028]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [23.259176452290955, -0.0, 2.0413109480321778]\n",
      "Error del epoch:  8.43349580011\n",
      "Epoch:  56\n",
      "ypred [0.62365936617564621, 0.32551522635741104, 0.050825407466942724]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [21.540431394932369, -0.0, 1.7554473836809585]\n",
      "Error del epoch:  7.7652929262\n",
      "Epoch:  57\n",
      "ypred [0.55842487986918532, 0.39256631162186506, 0.049008808508949411]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [19.287312059156651, -0.0, 1.6927042784715998]\n",
      "Error del epoch:  6.99333877921\n",
      "Epoch:  58\n",
      "ypred [0.50402292226563683, 0.4517636368094804, 0.044213440924882816]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [17.408335010042279, -0.0, 1.5270781497541206]\n",
      "Error del epoch:  6.3118043866\n",
      "Epoch:  59\n",
      "ypred [0.45373399007858778, 0.50644527727018174, 0.039820732651230456]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [15.671416826094966, -0.0, 1.3753593809223676]\n",
      "Error del epoch:  5.68225873567\n",
      "Epoch:  60\n",
      "ypred [0.40857145820974949, 0.55557034413820261, 0.035858197652047813]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [14.111558236449133, -0.0, 1.2384982706285907]\n",
      "Error del epoch:  5.11668550236\n",
      "Epoch:  61\n",
      "ypred [0.36859535457113957, 0.59918966475520241, 0.032214980673658022]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [12.730832531735409, -0.0, 1.1126660140538436]\n",
      "Error del epoch:  4.61449951526\n",
      "Epoch:  62\n",
      "ypred [0.33388044494987745, 0.6368168845269091, 0.029302670523213392]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [11.531822030757104, -0.0, 1.0120783849750079]\n",
      "Error del epoch:  4.18130013858\n",
      "Epoch:  63\n",
      "ypred [0.30363423140063794, 0.66972345412432577, 0.026642314475036271]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [10.487154824187202, -0.0, 0.92019294229616999]\n",
      "Error del epoch:  3.80244925549\n",
      "Epoch:  64\n",
      "ypred [0.183230553846118, 0.81329375352155753, 0.0034756926323244986]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [6.3285591280067113, -0.0, 0.12004617064529437]\n",
      "Error del epoch:  2.14953509955\n",
      "Epoch:  65\n",
      "ypred [0.25118364213082389, 0.72777560902358351, 0.021040748845592736]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [8.6755756496157925, -0.0, 0.72672171955940257]\n",
      "Error del epoch:  3.13409912306\n",
      "Epoch:  66\n",
      "ypred [0.2344643520688153, 0.74498340798860296, 0.020552239942581707]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [8.0981118286824252, -0.0, 0.7098492197913816]\n",
      "Error del epoch:  2.93598701616\n",
      "Epoch:  67\n",
      "ypred [0.16934963076863949, 0.82286338989781538, 0.0077869793335452906]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [5.8491290296787257, -0.0, 0.26895273799311142]\n",
      "Error del epoch:  2.03936058922\n",
      "Epoch:  68\n",
      "ypred [0.20268487808308297, 0.77952652075606388, 0.017788601160853214]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [7.000487682741336, -0.0, 0.61439651787295779]\n",
      "Error del epoch:  2.53829473354\n",
      "Epoch:  69\n",
      "ypred [0.18291283721056928, 0.80219689203064615, 0.014890270758784728]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [6.3175855841745507, -0.0, 0.51429173219734281]\n",
      "Error del epoch:  2.27729243879\n",
      "Epoch:  70\n",
      "ypred [0.17713837793274995, 0.80731551069576024, 0.015546111371489863]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [6.118142826376431, -0.0, 0.53694366447026665]\n",
      "Error del epoch:  2.21836216362\n",
      "Epoch:  71\n",
      "ypred [0.15660475877917879, 0.83117999135133891, 0.012215249869482281]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [5.4089367458529818, -0.0, 0.42189978385001042]\n",
      "Error del epoch:  1.94361217657\n",
      "Epoch:  72\n",
      "ypred [0.15695172288717735, 0.82927345342925041, 0.013774823683572147]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [5.4209204615962037, -0.0, 0.47576555508621832]\n",
      "Error del epoch:  1.96556200556\n",
      "Epoch:  73\n",
      "ypred [0.14548133528825383, 0.842169518456378, 0.01234914625536814]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [5.0247473091540282, -0.0, 0.4265244011822088]\n",
      "Error del epoch:  1.81709057011\n",
      "Epoch:  74\n",
      "ypred [0.12196811689392904, 0.8695495013718989, 0.0084823817341720641]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [4.2126295167077439, -0.0, 0.29297108601284366]\n",
      "Error del epoch:  1.50186686757\n",
      "Epoch:  75\n",
      "ypred [0.12400686409148683, 0.86635214313779207, 0.0096409927707211338]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [4.2830453502899424, -0.0, 0.33298809353288766]\n",
      "Error del epoch:  1.53867781461\n",
      "Epoch:  76\n",
      "ypred [0.12703245074080169, 0.86188542016355518, 0.011082129095643156]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [4.3875454110340559, -0.0, 0.38276317881395272]\n",
      "Error del epoch:  1.59010286328\n",
      "Epoch:  77\n",
      "ypred [0.12154816488854353, 0.8677863794846139, 0.010665455626842454]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [4.1981248882971389, -0.0, 0.36837178704535345]\n",
      "Error del epoch:  1.52216555845\n",
      "Epoch:  78\n",
      "ypred [0.11554606362906042, 0.87438157993460019, 0.010072356436339509]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [3.99081965499624, -0.0, 0.34788686672456975]\n",
      "Error del epoch:  1.44623550724\n",
      "Epoch:  79\n",
      "ypred [0.015710034186621195, 0.9841689567125399, 0.00012100910083894729]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.54260535792811204, -0.0, 0.0041795062756255991]\n",
      "Error del epoch:  0.182261621401\n",
      "Epoch:  80\n",
      "ypred [0.062307856988069121, 0.93510362693223337, 0.0025885160796974859]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [2.1520371401569927, -0.0, 0.08940417807130227]\n",
      "Error del epoch:  0.747147106076\n",
      "Epoch:  81\n",
      "ypred [0.014335535792312263, 0.98555403080610104, 0.00011043340158681764]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.49513186523191199, -0.0, 0.0038142345639364693]\n",
      "Error del epoch:  0.166315366599\n",
      "Epoch:  82\n",
      "ypred [0.014791124415636608, 0.98508819269712611, 0.00012068288723730624]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.51086733882097679, -0.0, 0.0041682392569815409]\n",
      "Error del epoch:  0.171678526026\n",
      "Epoch:  83\n",
      "ypred [0.10442548723956323, 0.88641049710901765, 0.0091640156514190343]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [3.6067285536968732, -0.0, 0.31651388746382381]\n",
      "Error del epoch:  1.30774748039\n",
      "Epoch:  84\n",
      "ypred [0.099836120873272372, 0.89145423164448456, 0.0087096474822431023]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [3.4482174549772298, -0.0, 0.30082056686769132]\n",
      "Error del epoch:  1.24967934061\n",
      "Epoch:  85\n",
      "ypred [0.094969986766047954, 0.89685883573682423, 0.0081711774971278059]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [3.2801471371401569, -0.0, 0.28222247245642323]\n",
      "Error del epoch:  1.18745653653\n",
      "Epoch:  86\n",
      "ypred [0.08395061171360596, 0.90954599633468614, 0.0065033919517079129]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [2.8995514061922059, -0.0, 0.22461920042850139]\n",
      "Error del epoch:  1.04139020221\n",
      "Epoch:  87\n",
      "ypred [0.07040924987048508, 0.9249648185200533, 0.0046259316094617057]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [2.4318493374100782, -0.0, 0.15977401747734715]\n",
      "Error del epoch:  0.863874451629\n",
      "Epoch:  88\n",
      "ypred [0.027666483511937293, 0.97166390163602168, 0.00066961485204104125]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.95556648765228547, -0.0, 0.023127677645356726]\n",
      "Error del epoch:  0.326231388433\n",
      "Epoch:  89\n",
      "ypred [0.045688947163112954, 0.95234717063210828, 0.0019638822047787774]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [1.5780403297856471, -0.0, 0.067830088336798391]\n",
      "Error del epoch:  0.548623472707\n",
      "Epoch:  90\n",
      "ypred [0.024096198361574724, 0.97536682969704902, 0.00053697194137638474]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.83225320717784257, -0.0, 0.018546353813540042]\n",
      "Error del epoch:  0.283599853664\n",
      "Epoch:  91\n",
      "ypred [0.064732481152507945, 0.93096700538368748, 0.0043005134638046463]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [2.235780692014242, -0.0, 0.14853447290965149]\n",
      "Error del epoch:  0.794771721641\n",
      "Epoch:  92\n",
      "ypred [0.0077098585929028067, 0.99223075493512591, 5.938647197123027e-05]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.26628908197665074, -0.0, 0.002051136076296953]\n",
      "Error del epoch:  0.089446739351\n",
      "Epoch:  93\n",
      "ypred [0.0076153384769292991, 0.99232600313629149, 5.8658386779229941e-05]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.26302447282622077, -0.0, 0.0020259889046540082]\n",
      "Error del epoch:  0.0883501539103\n",
      "Epoch:  94\n",
      "ypred [0.0089179214550909897, 0.9910014476414909, 8.0630903418018378e-05]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.30801409504476424, -0.0, 0.0027848927436745765]\n",
      "Error del epoch:  0.103599662596\n",
      "Epoch:  95\n",
      "ypred [0.0074398481373255509, 0.99250271330697437, 5.7438555699967034e-05]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.25696325122717995, -0.0, 0.0019838574317677837]\n",
      "Error del epoch:  0.0863157028863\n",
      "Epoch:  96\n",
      "ypred [0.0093203848810977357, 0.9905895913052899, 9.0023813612386124e-05]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.32191468932274092, -0.0, 0.0031093123685753208]\n",
      "Error del epoch:  0.108341333897\n",
      "Epoch:  97\n",
      "ypred [0.0073037024462180439, 0.9926395272090307, 5.677034475130161e-05]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.25226094564488721, -0.0, 0.0019607782432271978]\n",
      "Error del epoch:  0.0847405746294\n",
      "Epoch:  98\n",
      "ypred [0.0071447273889463387, 0.99280023918294247, 5.5033428111256304e-05]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.24677014168941164, -0.0, 0.0019007872677800734]\n",
      "Error del epoch:  0.0828903096524\n",
      "Epoch:  99\n",
      "ypred [0.0070691864515214963, 0.99287632461465569, 5.4488933822807903e-05]\n",
      "ytrain [ 0.  1.  0.]\n",
      "ERRORES CE VECOR [0.24416105014303308, -0.0, 0.001881981101303048]\n",
      "Error del epoch:  0.0820143437481\n",
      "Epoch:  100\n",
      "ypred [0.076854784919172262, 0.91640006894331183, 0.0067451461375160702]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [2.6544702312022443, 31.651337069513783, -0.0]\n",
      "Error del epoch:  11.4352691002\n",
      "Epoch:  101\n",
      "ypred [0.0069835454294605035, 0.99289738276249995, 0.00011907180803949126]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.24120311403183683, 34.293460686326029, -0.0]\n",
      "Error del epoch:  11.5115546001\n",
      "Epoch:  102\n",
      "ypred [0.0069802606418685846, 0.99243036253102834, 0.00058937682710303446]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.24108966148769478, 34.277330378979336, -0.0]\n",
      "Error del epoch:  11.5061400135\n",
      "Epoch:  103\n",
      "ypred [0.0069640547697648221, 0.99012626525554848, 0.002909679974686709]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.24052993049481838, 34.197749678389414, -0.0]\n",
      "Error del epoch:  11.4794265363\n",
      "Epoch:  104\n",
      "ypred [0.0068853202953404087, 0.97893205818997886, 0.014182621514680714]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.23781053808810276, 33.811115463633371, -0.0]\n",
      "Error del epoch:  11.3496420006\n",
      "Epoch:  105\n",
      "ypred [0.0065295372082585573, 0.92834799604519613, 0.065122466746545288]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.22552222559829166, 32.06400385206846, -0.0]\n",
      "Error del epoch:  10.7631753592\n",
      "Epoch:  106\n",
      "ypred [0.0053279983361986276, 0.75751717473730551, 0.23715482692649584]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.18402254316642055, 26.163716313556279, -0.0]\n",
      "Error del epoch:  8.78257961891\n",
      "Epoch:  107\n",
      "ypred [0.0034010449749538128, 0.48354932152994412, 0.51304963349510213]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.11746793189896435, 16.701201892233509, -0.0]\n",
      "Error del epoch:  5.60622327471\n",
      "Epoch:  108\n",
      "ypred [0.0021188065796656184, 0.30124490901929429, 0.69663628440104008]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.073180986679136306, 10.404630552722619, -0.0]\n",
      "Error del epoch:  3.49260384647\n",
      "Epoch:  109\n",
      "ypred [0.0014762577307366723, 0.20988943967456525, 0.78863430259469802]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.050988135663172188, 7.2493244245729045, -0.0]\n",
      "Error del epoch:  2.43343752008\n",
      "Epoch:  110\n",
      "ypred [0.0011206297798827642, 0.15932743428537499, 0.83955193593474231]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.038705181388848771, 5.5029746263573927, -0.0]\n",
      "Error del epoch:  1.84722660258\n",
      "Epoch:  111\n",
      "ypred [0.00089958448882934759, 0.1278999461741013, 0.87120046933706941]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.031070547508006866, 4.4175076418283972, -0.0]\n",
      "Error del epoch:  1.48285939645\n",
      "Epoch:  112\n",
      "ypred [0.00075004455303003415, 0.10663885288368662, 0.89261110256328335]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.025905621103325078, 3.6831754947594284, -0.0]\n",
      "Error del epoch:  1.23636037195\n",
      "Epoch:  113\n",
      "ypred [0.00064252732059546635, 0.091352408517505215, 0.90800506416189919]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.022192107453667901, 3.1552004109226468, -0.0]\n",
      "Error del epoch:  1.05913083946\n",
      "Epoch:  114\n",
      "ypred [0.00056165561992358869, 0.079854337695495575, 0.91958400668458073]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.019398897867485772, 2.7580711138284091, -0.0]\n",
      "Error del epoch:  0.925823337232\n",
      "Epoch:  115\n",
      "ypred [0.00049868743757065651, 0.070901729870852651, 0.92859958269157661]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.017224053897203887, 2.4488589940217391, -0.0]\n",
      "Error del epoch:  0.82202768264\n",
      "Epoch:  116\n",
      "ypred [0.00044830637569947266, 0.063738717189404714, 0.93581297643489592]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.015483953666696908, 2.2014573007032996, -0.0]\n",
      "Error del epoch:  0.738980418123\n",
      "Epoch:  117\n",
      "ypred [0.00040710132136570856, 0.057880318899047906, 0.94171257977958645]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.014060781508722883, 1.9991153921203386, -0.0]\n",
      "Error del epoch:  0.671058724543\n",
      "Epoch:  118\n",
      "ypred [0.00037278649131098165, 0.053001549899057213, 0.94662566360963185]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.012875589266433309, 1.8306086805472379, -0.0]\n",
      "Error del epoch:  0.614494756605\n",
      "Epoch:  119\n",
      "ypred [0.00034377431688963279, 0.048876694932168001, 0.95077953075094246]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.011873544261364194, 1.6881412371844149, -0.0]\n",
      "Error del epoch:  0.566671593815\n",
      "Epoch:  120\n",
      "ypred [0.00031892856520811664, 0.045344208165020307, 0.95433686326977163]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.011015402399672832, 1.5661334666159197, -0.0]\n",
      "Error del epoch:  0.525716289672\n",
      "Epoch:  121\n",
      "ypred [0.00029741502349001374, 0.04228548398521547, 0.95741710099129451]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.010272350992808692, 1.4604888761159338, -0.0]\n",
      "Error del epoch:  0.49025374237\n",
      "Epoch:  122\n",
      "ypred [0.00027860764644954412, 0.039611513345412165, 0.96010987900813838]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0096227672026331368, 1.3681332021012111, -0.0]\n",
      "Error del epoch:  0.459251989768\n",
      "Epoch:  123\n",
      "ypred [0.00026202758101698958, 0.037254214500535059, 0.96248375791844798]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.009050112030045146, 1.2867149844020196, -0.0]\n",
      "Error del epoch:  0.431921698811\n",
      "Epoch:  124\n",
      "ypred [0.00024730239722643769, 0.035160636590286606, 0.96459206101248696]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0085415221997293123, 1.2144053650946238, -0.0]\n",
      "Error del epoch:  0.407648962431\n",
      "Epoch:  125\n",
      "ypred [0.00023413813503057228, 0.033288985347762479, 0.96647687651720693]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0080868446913423403, 1.1497608213398263, -0.0]\n",
      "Error del epoch:  0.38594922201\n",
      "Epoch:  126\n",
      "ypred [0.0002222997079387839, 0.031605836953556468, 0.9681718633385048]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.007677959905151608, 1.091626935312892, -0.0]\n",
      "Error del epoch:  0.366434965073\n",
      "Epoch:  127\n",
      "ypred [0.00021159689114957992, 0.030084145874787565, 0.96970425723406284]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0073082977092735965, 1.0390695874011624, -0.0]\n",
      "Error del epoch:  0.34879262837\n",
      "Epoch:  128\n",
      "ypred [0.00020187412407781887, 0.028701795022162475, 0.97109633085375968]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0069724852314422409, 0.99132488040303024, -0.0]\n",
      "Error del epoch:  0.332765788545\n",
      "Epoch:  129\n",
      "ypred [0.00019300296987803282, 0.027440523669950322, 0.97236647336017168]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0066660864201710576, 0.94776211119566811, -0.0]\n",
      "Error del epoch:  0.318142732539\n",
      "Epoch:  130\n",
      "ypred [0.0001848764588183998, 0.026285123215610714, 0.97353000032557091]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0063854066718116243, 0.90785599325665411, -0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error del epoch:  0.304747133309\n",
      "Epoch:  131\n",
      "ypred [0.00017740478895300518, 0.025222825915600308, 0.97459976929544667]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0061273443370341669, 0.87116554434667737, -0.0]\n",
      "Error del epoch:  0.292430962895\n",
      "Epoch:  132\n",
      "ypred [0.00017051201912382378, 0.024242834707337003, 0.97558665327353922]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0058892765011624836, 0.83731784713549273, -0.0]\n",
      "Error del epoch:  0.281069041212\n",
      "Epoch:  133\n",
      "ypred [0.00016413349723223182, 0.023335957569352368, 0.97649990893341543]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0056689701598187465, 0.80599542044898487, -0.0]\n",
      "Error del epoch:  0.27055479687\n",
      "Epoch:  134\n",
      "ypred [0.00015821384004345633, 0.022494320296572345, 0.97734746586338417]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.005464512443841104, 0.77692629887881315, -0.0]\n",
      "Error del epoch:  0.260796937108\n",
      "Epoch:  135\n",
      "ypred [0.00015270533140974797, 0.021711138764988029, 0.97813615590360226]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0052742552958720164, 0.74987616708279881, -0.0]\n",
      "Error del epoch:  0.25171680746\n",
      "Epoch:  136\n",
      "ypred [0.00014756664126348631, 0.020980536802333589, 0.97887189655640305]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.005096771225947554, 0.72464206926099428, -0.0]\n",
      "Error del epoch:  0.243246280162\n",
      "Epoch:  137\n",
      "ypred [0.00014276179291656605, 0.020297399362129952, 0.97955983884495346]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.004930817643281819, 0.70104733796680918, -0.0]\n",
      "Error del epoch:  0.23532605187\n",
      "Epoch:  138\n",
      "ypred [0.00013825932431302116, 0.019657253273358061, 0.98020448740232891]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0047753078869588765, 0.67893747534664017, -0.0]\n",
      "Error del epoch:  0.227904261078\n",
      "Epoch:  139\n",
      "ypred [0.00013403160205773627, 0.019056169711330808, 0.98080979868661144]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0046292875333238037, 0.65817678460312445, -0.0]\n",
      "Error del epoch:  0.220935357379\n",
      "Epoch:  140\n",
      "ypred [0.00013005425673458192, 0.018490683913093817, 0.98137926183017155]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0044919148925620317, 0.63864559706331947, -0.0]\n",
      "Error del epoch:  0.214379170652\n",
      "Epoch:  141\n",
      "ypred [0.00012630571522698287, 0.017957728684311246, 0.98191596560046179]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0043624448556240265, 0.62023797558789973, -0.0]\n",
      "Error del epoch:  0.208200140148\n",
      "Epoch:  142\n",
      "ypred [0.00012276681115404501, 0.017454579012363119, 0.98242265417648278]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0042402154391657874, 0.60285980157531072, -0.0]\n",
      "Error del epoch:  0.202366672338\n",
      "Epoch:  143\n",
      "ypred [0.00011942045862194139, 0.016978805681397199, 0.9829017738599809]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0041246365173209171, 0.58642717288241697, -0.0]\n",
      "Error del epoch:  0.196850603133\n",
      "Epoch:  144\n",
      "ypred [0.00011625137760880292, 0.016528236228460957, 0.98335551239393026]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0040151803368307709, 0.57086505529707487, -0.0]\n",
      "Error del epoch:  0.191626745211\n",
      "Epoch:  145\n",
      "ypred [0.00011324586169998929, 0.01610092192087113, 0.98378583221742888]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0039113734949049106, 0.55610614197688379, -0.0]\n",
      "Error del epoch:  0.186672505157\n",
      "Epoch:  146\n",
      "ypred [0.00011039158074929667, 0.015695109699237108, 0.98419449872001363]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0038127901233806845, 0.5420898843955444, -0.0]\n",
      "Error del epoch:  0.181967558173\n",
      "Epoch:  147\n",
      "ypred [0.00010767741249210501, 0.015309218236775361, 0.9845831043507326]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0037190460728473776, 0.528761665460873, -0.0]\n",
      "Error del epoch:  0.177493570511\n",
      "Epoch:  148\n",
      "ypred [0.00010509329827584675, 0.014941817427544808, 0.98495308927417935]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0036297939297531235, 0.51607209106354968, -0.0]\n",
      "Error del epoch:  0.173233961664\n",
      "Epoch:  149\n",
      "ypred [0.00010263011897391348, 0.014591610744296645, 0.98530575913672946]\n",
      "ytrain [ 0.  0.  1.]\n",
      "ERRORES CE VECOR [0.0035447187306230782, 0.5039763807388381, -0.0]\n",
      "Error del epoch:  0.169173699823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "X_train,y_train = load_iris(return_X_y=True)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "#transform target to one hot vector\n",
    "import keras\n",
    "y_onehot = keras.utils.to_categorical(y_train)\n",
    "\n",
    "arquitectura=size_layers(3,4,32,16,3)\n",
    "modelo=NN_2ocultas(3, arquitectura)\n",
    "\"\"\"\n",
    "x_train=X_train[0]\n",
    "y_true=one_hot(y_train[0])\n",
    "modelo.training(x_train, y_true, 1, \"ce\")\n",
    "\"\"\"\n",
    "#i=0\n",
    "print (X_train.shape[0])\n",
    "errores = modelo.entrenamiento(X_train,y_onehot)\n",
    "\n",
    "\n",
    "\n",
    "#prediccion = prediccion(modelo,X_train[0],y_onehot[0],arquitectura)\n",
    "#print(prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "### 2. Comparar back-propagation (BP) de Keras\n",
    "\n",
    "Keras es una de las librerı́as más populares para desarrollar nuevos modelos de redes neuronales o implementar eficientemente modelos conocidos con fines prácticos, puesto que ofrece una interfaz para poder trabajar de una manera mucho mas simple además de permitir también el manejo de configuraciones mas específicas.  \n",
    "Como actividad pedagógica ahora se les pide comparar el algoritmo implementado por ustedes con el de alto nivel de la librería __[keras](https://keras.io/)__ . Se les pedirá comparar sobre el mismo dataset con la misma arquitectura utilizada anteriormente, es decir, dos capas ocultas (con 32 y 16 neuronas respectivamente), 3 neuronas en la capa de salida con función de activación softmax, optimizador Gradiente Descentente (GD) con tasa de aprendizaje fija.\n",
    "\n",
    "<img src=\"https://i.imgur.com/hUjFUDU.png\" width=\"40%\" height=\"40%\" />\n",
    "\n",
    "\n",
    "> a) Defina, a través de la interfaz de keras, la arquitectura de la red, con las funciones de activación para comparar con la sección anterior.\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation=\"sigmoid or relu\"))\n",
    "model.add(Dense(16, activation=\"sigmoid or relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "```\n",
    "\n",
    "> b) Defina, a través de la interfaz de keras, el optimizador de la red, en conjunto con la función de error, para poder comparar con la sección anterior.\n",
    "```python\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.1),loss=\"categorical_crossentropy or mse\", metrics=[\"accuracy\"])\n",
    "```\n",
    "\n",
    "> c) Entrene (ajuste) los pesos de la red definida mediante keras, reportando los mismos gráficos de la sección anterior para poder comparar. Si hay diferencias en la convergencia del algoritmo ¿A qué podría deverse? si hay una gran diferencia en los tiempos de entrenamiento ¿A qué podría deverse?\n",
    "```python\n",
    "model.fit(X_train, y_onehot, epochs=100, batch_size=1, verbose=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 1.0953 - acc: 0.4600\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6828 - acc: 0.6867\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.4517 - acc: 0.7867\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3567 - acc: 0.8667\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2933 - acc: 0.9000\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2329 - acc: 0.9333\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1891 - acc: 0.9333\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.1619 - acc: 0.9333\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1381 - acc: 0.9467\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1215 - acc: 0.9533\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1173 - acc: 0.9600\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0922 - acc: 0.9667\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1025 - acc: 0.9600\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1069 - acc: 0.9533\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0763 - acc: 0.9733\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0861 - acc: 0.9733\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0961 - acc: 0.9667\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0718 - acc: 0.9800\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1213 - acc: 0.9467\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0690 - acc: 0.9600\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0673 - acc: 0.9800\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0865 - acc: 0.9667\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0856 - acc: 0.9600\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0666 - acc: 0.9733\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0725 - acc: 0.9733\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0773 - acc: 0.9667\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0945 - acc: 0.9600\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0786 - acc: 0.9667\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0884 - acc: 0.9600\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0775 - acc: 0.9667\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0803 - acc: 0.9667\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0661 - acc: 0.9733\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0789 - acc: 0.9600\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1183 - acc: 0.9400\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0802 - acc: 0.9733\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0674 - acc: 0.9800\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0733 - acc: 0.9733\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0629 - acc: 0.9800\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0816 - acc: 0.9467\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0823 - acc: 0.9600\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0823 - acc: 0.9733\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0607 - acc: 0.9733\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0668 - acc: 0.9733\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.0597 - acc: 0.9800\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0666 - acc: 0.9800\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0800 - acc: 0.9667\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0601 - acc: 0.9733\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0902 - acc: 0.9600\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0579 - acc: 0.9733\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0694 - acc: 0.9600\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0753 - acc: 0.9733\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0710 - acc: 0.9800\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0857 - acc: 0.9733\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0756 - acc: 0.9733\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0595 - acc: 0.9800\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0512 - acc: 0.9800\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0855 - acc: 0.9600\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0672 - acc: 0.9667\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0704 - acc: 0.9600\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0753 - acc: 0.9533\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0708 - acc: 0.9600\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0443 - acc: 0.9867\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0771 - acc: 0.9667\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0693 - acc: 0.9667\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0764 - acc: 0.9667\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0655 - acc: 0.9733\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0654 - acc: 0.9733\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0551 - acc: 0.9800\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0609 - acc: 0.9667\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0615 - acc: 0.9667\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0724 - acc: 0.9667\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0641 - acc: 0.9733\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0548 - acc: 0.9867\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0653 - acc: 0.9800\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0576 - acc: 0.9600\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0601 - acc: 0.9733\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0771 - acc: 0.9667\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0672 - acc: 0.9667\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0583 - acc: 0.9733\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0634 - acc: 0.9667\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0642 - acc: 0.9733\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0710 - acc: 0.9733\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0647 - acc: 0.9733\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0481 - acc: 0.9733\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0698 - acc: 0.9667\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0673 - acc: 0.9733\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0561 - acc: 0.9733\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0598 - acc: 0.9667\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0585 - acc: 0.9667\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0692 - acc: 0.9800\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0583 - acc: 0.9733\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0555 - acc: 0.9800\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0501 - acc: 0.9733\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0734 - acc: 0.9733\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0557 - acc: 0.9800\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0697 - acc: 0.9733\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0519 - acc: 0.9733\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0747 - acc: 0.9667\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0573 - acc: 0.9600\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0658 - acc: 0.9667\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0496 - acc: 0.9800\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0551 - acc: 0.9867\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0632 - acc: 0.9667\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0524 - acc: 0.9867\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.0547 - acc: 0.9800\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0629 - acc: 0.9667\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0625 - acc: 0.9733\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0525 - acc: 0.9867\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0584 - acc: 0.9667\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0584 - acc: 0.9733\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0447 - acc: 0.9800\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0663 - acc: 0.9667\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0485 - acc: 0.9733\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0564 - acc: 0.9867\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0636 - acc: 0.9733\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0529 - acc: 0.9800\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0615 - acc: 0.9667\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0623 - acc: 0.9733\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0641 - acc: 0.9733\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0626 - acc: 0.9667\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0567 - acc: 0.9800\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0681 - acc: 0.9800\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0558 - acc: 0.9667\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0604 - acc: 0.9800\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0536 - acc: 0.9667\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0569 - acc: 0.9867\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0597 - acc: 0.9733\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.0615 - acc: 0.9733\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0497 - acc: 0.9800\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0520 - acc: 0.9867\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0465 - acc: 0.9800\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0527 - acc: 0.9800\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.0444 - acc: 0.9733\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0765 - acc: 0.9733\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0495 - acc: 0.9800\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0544 - acc: 0.9800\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0527 - acc: 0.9800\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0605 - acc: 0.9733\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0563 - acc: 0.9800\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0547 - acc: 0.9800\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0464 - acc: 0.9867\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0599 - acc: 0.9733\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.0530 - acc: 0.9867\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0423 - acc: 0.9867\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0340 - acc: 0.9800\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0709 - acc: 0.9667\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0598 - acc: 0.9733\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0559 - acc: 0.9733\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0601 - acc: 0.9667\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0481 - acc: 0.9800\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0570 - acc: 0.9733\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0489 - acc: 0.9667\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0441 - acc: 0.9733\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0459 - acc: 0.9933\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0591 - acc: 0.9667\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.0417 - acc: 0.9867\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0480 - acc: 0.9733\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0518 - acc: 0.9800\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0590 - acc: 0.9733\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0492 - acc: 0.9867\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0539 - acc: 0.9800\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0452 - acc: 0.9800\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0630 - acc: 0.9733\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0510 - acc: 0.9800\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0416 - acc: 0.9933\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0512 - acc: 0.9867\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0658 - acc: 0.9800\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0535 - acc: 0.9667\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0426 - acc: 0.9867\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0488 - acc: 0.9800\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0543 - acc: 0.9800\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0594 - acc: 0.9733\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0367 - acc: 0.9800\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0495 - acc: 0.9733\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0488 - acc: 0.9800\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0562 - acc: 0.9867\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0450 - acc: 0.9867\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0615 - acc: 0.9867\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.0530 - acc: 0.9800\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0486 - acc: 0.9867\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0472 - acc: 0.9867\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0614 - acc: 0.9800\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0459 - acc: 0.9867\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0613 - acc: 0.9800\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0488 - acc: 0.9733\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0471 - acc: 0.9800\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0524 - acc: 0.9733\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0536 - acc: 0.9733\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0465 - acc: 0.9733\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0542 - acc: 0.9867\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0497 - acc: 0.9867\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0548 - acc: 0.9800\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0539 - acc: 0.9733\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0472 - acc: 0.9867\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0386 - acc: 0.9867\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0466 - acc: 0.9867\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0511 - acc: 0.9800\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0479 - acc: 0.9933\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0470 - acc: 0.9867\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0460 - acc: 0.9800\n",
      "dict_keys(['loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXm4JVV5Lv5+VbWH09379AxCN1MUkUZIEwZRcwMY4wOO\nIPk5RW9GjZr5Rm80yTVefzHGe7nXaGIGTEjihANOGBkEAiZGMIIMgswIdjN2A93nnD5nn13Dun+s\nWlWrVq2qWnXOHqrPWe/z9NP77F3D2lW117e+9/u+9yPGGCwsLCwsLJYKZ9IDsLCwsLA4uGENiYWF\nhYXFsmANiYWFhYXFsmANiYWFhYXFsmANiYWFhYXFsmANiYWFhYXFsmANiYVFCYjon4joTw23fYiI\nXjrqMVlYNA3WkFhYWFhYLAvWkFhYrAIQkTfpMVisXFhDYnHQI6aU3k1EtxPRASL6ByI6lIiuIKJZ\nIrqGiDZK27+aiO4kon1EdD0RHS99djIRfT/e7/MAusq5XklEt8b7foeITjIc4yuI6BYimiGiXUT0\nfuXzn46Pty/+/Jfi96eI6P8Q0cNEtJ+Ivh2/dxYR7dZch5fGr99PRJcS0aeJaAbALxHR6UR0Q3yO\nx4jor4ioLe1/AhFdTURPE9ETRPSHRPQsIponos3SdqcQ0R4iapl8d4uVD2tILFYKLgDwcwCeC+BV\nAK4A8IcAtoA/578NAET0XACXAPhdAFsBXA7g60TUjifVrwL4FIBNAL4YHxfxvj8F4GIAvw5gM4C/\nA3AZEXUMxncAwH8FsAHAKwC8g4jOi497ZDzev4zHtBPArfF+FwI4BcCL4jH9dwCR4TV5DYBL43N+\nBkAI4Pfia/JCAD8L4J3xGHoArgFwJYDDATwHwLWMsccBXA/gddJx3wzgc4wx33AcFisc1pBYrBT8\nJWPsCcbYIwD+HcB3GWO3MMYWAXwFwMnxdq8H8A3G2NXxRHghgCnwifoMAC0Af8EY8xljlwL4nnSO\ntwL4O8bYdxljIWPsnwEsxvuVgjF2PWPsB4yxiDF2O7gxOzP++BcAXMMYuyQ+71OMsVuJyAHwKwB+\nhzH2SHzO78TfyQQ3MMa+Gp9zgTF2M2PsRsZYwBh7CNwQijG8EsDjjLH/wxjrM8ZmGWPfjT/7Z3Dj\nASJyAbwR3NhaWACwhsRi5eAJ6fWC5u918evDATwsPmCMRQB2AdgWf/YIyyqZPiy9PgrA78fU0D4i\n2gfgiHi/UhDRC4joupgS2g/g7eCeAeJjPKDZbQs4tab7zAS7lDE8l4j+hYgej+muPzMYAwB8DcAO\nIvoJcK9vP2PsP5c4JosVCGtILFYbHgU3CAAAIiLwSfQRAI8B2Ba/J3Ck9HoXgA8yxjZI/9Ywxi4x\nOO9nAVwG4AjG2HoAfwtAnGcXgGdr9tkLoF/w2QEAa6Tv4YLTYjJUae+/AXA3gGMZY9Pg1F/VGMAY\n6wP4Arjn9BZYb8RCgTUkFqsNXwDwCiL62ThY/Pvg9NR3ANwAIADw20TkEdFrAZwu7fsJAG+PvQsi\norVxEL1ncN4egKcZY30iOh3Am6TPPgPgpUT0uvi8m4loZ+wtXQzg/xLR4UTkEtEL45jMvQC68flb\nAP4YQFWspgdgBsAcET0PwDukz/4FwLOI6HeJqENEPSJ6gfT5JwH8EoBXA/i0wfe1WEWwhsRiVYEx\ndg843/+X4Cv+VwF4FWNswBgbAHgt+IT5DHg85cvSvjeBx0n+Kv78/nhbE7wTwAeIaBbA+8ANmjju\njwG8HNyoPQ0eaP/J+ON3AfgBeKzmaQAfBuAwxvbHx/x7cG/qAIBMFpcG7wI3YLPgRvHz0hhmwWmr\nVwF4HMB9AM6WPv8P8CD/9+P4ioVFArKNrSwsLExARP8K4LOMsb+f9FgsmgVrSCwsLCpBRKcBuBo8\nxjM76fFYNAuW2rKwsCgFEf0zeI3J71ojYqGD9UgsLCwsLJYF65FYWFhYWCwLq0LIbcuWLezoo4+e\n9DAsLCwsDircfPPNexljan1SDqvCkBx99NG46aabJj0MCwsLi4MKRPRw9VaW2rKwsLCwWCasIbGw\nsLCwWBasIbGwsLCwWBZWRYxEB9/3sXv3bvT7/UkPZaTodrvYvn07Wi3bg8jCwmI0WLWGZPfu3ej1\nejj66KORFXtdOWCM4amnnsLu3btxzDHHTHo4FhYWKxSrltrq9/vYvHnzijUiAEBE2Lx584r3uiws\nLCaLVWtIAKxoIyKwGr6jhYXFZLGqDYmFxcGCW3ftwx2P7J/0MHDdPU9i9zPzkx6GhYQnZvq46s7H\nJzoGa0gmhH379uGv//qva+/38pe/HPv27RvBiCyajA9+44f48JV3T3oY+K3P3oKLv/3QpIdhIeFz\n/7kLb//0zVgMwomNwRqSCaHIkIRh+cNw+eWXY8OGDaMalkVD0fcjLAbRRMfAGMP8IMC+hcFEx2GR\nxbwfgDFgth9MbAzWkEwI73nPe/DAAw9g586dOO2003D22WfjTW96E0488UQAwHnnnYdTTjkFJ5xw\nAi666KJkv6OPPhp79+7FQw89hOOPPx5vfetbccIJJ+BlL3sZFhYWJvV1LEYMP4wQRpNV6g4ihogB\nMwuTm7As8lj0+QJjZsGf2BhWbfqvjP/59Tvxw0dnhnrMHYdP409edULh53/+53+OO+64A7feeiuu\nv/56vOIVr8Add9yRpOlefPHF2LRpExYWFnDaaafhggsuwObNmzPHuO+++3DJJZfgE5/4BF73utfh\nS1/6Et785jcP9XtYNANBxBBM2JAIj2imP7kJyyKP9L5MzsBbQ9IQnH766Zlaj4997GP4yle+AgDY\ntWsX7rvvvpwhOeaYY7Bz504AwCmnnIKHHnpobOO1GC+4RzJZamvR57TrJFe+FnmI2Ij1SCaMMs9h\nXFi7dm3y+vrrr8c111yDG264AWvWrMFZZ52lrQXpdDrJa9d1LbW1ghGEDEHYDI9kkly8RR5N8BRt\njGRC6PV6mJ3Vdy3dv38/Nm7ciDVr1uDuu+/GjTfeOObRWTQNfhghmnA302TCsh5Jo5DGSCy1teqw\nefNmvPjFL8bzn/98TE1N4dBDD00+O+ecc/C3f/u3OOmkk3DcccfhjDPOmOBILZqAZsRIOIUyuxgg\njBhcxxa7NgGDcPIeiTUkE8RnP/tZ7fudTgdXXHGF9jMRB9myZQvuuOOO5P13vetdQx+fRXPgB5PP\n2hpI6cdz/QDr11gh0CagCbErS21ZWBwE8KOoMTESwGZuNQk2RmJhYWGEIGQT90gEFw8A+22cpDFI\nY1e2IHEiYBMOXo4Dq+E7rnQwxhoVIwGsR9IkJOm/1iMZP7rdLp566qkVPdGKfiTdbnfSQ7FYBvyY\n0pp4HYlEbdkU4OZAeIqTvCerNti+fft27N69G3v27Jn0UEYK0SHR4uBFEBuQRnkkltpqDJqQlr1q\nDUmr1bJdAy0OCviB8EiaEyOZpByHRRaW2rKwsKiE3xiPRDIk1iNpDGyw3cLCohJB2BCPJF75eg7Z\nYHtDwBjDIIjgOYQFP8zU+owT1pBYWDQcfly5HEZsoskhgtrasq5jpeQbAuGNbFnHdfdmJ2TgrSGx\nsGg4hCEBJuuVLAYRXIewcW3beiQNgTAkW3vckEwqdmUNiYVFwyHHRiYZJ1kMQnQ8B9Ndz8ZIGgJB\nNyaGZEL3xRoSC4uGo0keScdzMD3VsllbDYGgG7euEx6JNSQWFhYa+GFDPBI/QsdzMd1tWY+kIchR\nWxOKXY3UkBDROUR0DxHdT0Tv0Xx+FBFdS0S3E9H1RLRd+uzDRHRH/O/10vvHENF3ieg+Ivo8EbVH\n+R0sLCaNoDEeSYhOy8H0lGdjJA1BjtpaaR4JEbkAPg7gXAA7ALyRiHYom10I4JOMsZMAfADAh+J9\nXwHgpwDsBPACAO8moul4nw8D+Ahj7FgAzwD41VF9BwuLJiDrkUxOJkVQW71uC3OLAaIJpyNb5LO2\nVmKM5HQA9zPGHmSMDQB8DsBrlG12ALg2fn2d9PkOAN9ijAWMsQMAbgNwDhERgJcAuDTe7p8BnDfC\n72BhMXE0K0biYrrrgTHe4MpishAxko1rWnBoBXokALYB2CX9vTt+T8ZtAC6IX58PoEdEm+P3zyWi\nNUS0BcDZAI4AsBnAPsZYUHJMAAARvY2IbiKim1a6npbFyobshUyyJ0mStTXFG1pNqmbBIoWgtjot\nF9NTrYkJN47SkOj6cKq/gncBOJOIbgFwJoBHAASMsW8CuBzAdwBcAuAGAIHhMfmbjF3EGDuVMXbq\n1q1bl/gVLCwmD5namqhH4kc8RtLlhsQWJU4egtriadmTS4IYpSHZDe5FCGwH8Ki8AWPsUcbYaxlj\nJwP4o/i9/fH/H2SM7WSM/Ry4AbkPwF4AG4jIKzqmhcVKg0xtTbaOJELb5cF2wPYkaQKEIekmSRAr\nzyP5HoBj4yyrNoA3ALhM3oCIthCRGMN7AVwcv+/GFBeI6CQAJwH4JuP6ENcB+Pl4n18E8LURfgcL\ni4kjaIpHEoRJ+i9ghRubANGvfdJp2SMzJHEc4zcBXAXgLgBfYIzdSUQfIKJXx5udBeAeIroXwKEA\nPhi/3wLw70T0QwAXAXizFBf5AwD/jYjuB4+Z/MOovoOFRROQ9UgmnLXVcrA+jpHYosTJI0dtTchL\nHGk/EsbY5eCxDvm990mvL0WagSVv0wfP3NId80HwjDALi1WBRsVIPMd6JA1CakhcTm2txIJECwuL\n5SOTtdUAamtd18ZImoI0a2uyHok1JBYWDUdjPJK4INF1CL3O5Fa/FilEHQlPgmhhfhBmqNBxwRoS\nC4uGQ5ZImWwdCY+RAIiFG61HMmkMQp5J5ziE6dhTnEQtiTUkFhYNRxMq24MwQhgxdDwXANCzUvKN\ngIhbAUBvgrEra0gsLBqOJmhtDcI0OwjARPl4ixRCSBNAojgwiftiDYmFRcMhG49JeSSCi08MyQQz\nhCxSCP0zAAm1NYn7Yg2JhUXD0YR+JEmaaUtMWtYjaQJEAgRgPRILC4sSNCFGkqSZSpOWjZFMHot+\niLZqSGyMxMLCQkXQJI9EolFsT5LJg2fSZaktm7VlYWGRQ9YjmUywPR8jaSFiwIGBjZNMEkLaHwDW\ntr2J9SSxhsTCouHIxEgmVEciV1ADSGVSrN7WRCHHSByH0JuQcKM1JBYWDUcQRQkPPrkYiUJtCSl5\nGyeZKHgdiZv8PSkpeWtILCwaDj+M0I0NyeRiJEqw3Qo3NgJyHQmAiUnJW0NiYdFw+CHDVJuvOide\nR5IrfrPU1iQhU1vA5NKyrSGxsGg4gjBCN87MaU7WlvVImgC5IBGYXKGoNSQWFg2HHzJ0PeGRTChr\nS6G2elZKvhFY9MOMR9KzHomFhYUOfhih226KR6IYEiuTMlHIiszA5GIkI+2QaGFxsIMxhqcODMDi\n+bvX9RKaaVwIIpYE28NJpf/6WYkUz3Wwtu1OzCM5sBhgfhDm3ncI2Lyuk3vfDyPsm0/HumltG65D\nIx2jwPwgwIFFPlbXIWxa2y7dPggjPDOvv67rp1pJBh9jTEttHRiECMIInjs+P8EaEkNceNU9uPnh\nZ3DJ287IvP/l7+/G/77qHnz7D15i9GA+MdPHWf/7enzx7S/E87etX9aY3v3F2xBEDB95/c5lHWeY\neMs/fBcnHL4e7zn3eUbbX/ztH+GS//wxrv5vZ454ZOV49xdvw2IQ4WNvPDnz/sevux8XfvPe5O9n\nTXdxw3tfAqLxTEIAn1jWdfjko3okH73mPvzH/Xvxhbe/0OhYt+/eh9f/3Y24/t1n4dDprvEYVGoL\n4AH3/RWr3w9feTd+sHs/Pv1rLzA+VxX2zQ9wxoeuRd/X03z/89Un4BdfdHTmvV/+x+/h2/fvTf5+\nzc7D8dE3ZO/1R6+5D9+690l8+Z0vHtpY5wcBXvDBazG7mHpuH77gRLz+tCML93nHZ76Pq3/4hPaz\n047eiC++/UUA8orMQLa+p8pgDRPWkBji7sdn8fBTB3LvP/TUPB7b38ds38eGNdU37tF9C1jwQ/z4\n6fllG5If7T0w0darOjz01AGsbZs/Vvc+MYv7npxDGLGxrRCLxqG7krueXsB018O7z3ke/uO+vbjy\nzsex4IdYU+M7LheDkKHl8s6EatbWQ08dwIN7889lER56aj55/uoZkggOAZ50j6a7LcxWeCQPP3UA\n9zwxa3weEzy6r4++H+FNLzgSxx82nfnsQ5ffhQf3zOX2eWDPHE45aiPOO3kbPnPjw3hwT/6a3fvE\nLO59Ir/vcrBv3sfsYoDzT96GnzpqI/7/r/9Qe24Zu56ex/GHTeNNL8gam6/f9igeeDIdn0o3Amk2\n3Wzft4akiZjt+xhoaAUhXzGzEBgZEnHzh9EOczGIGmdI/IAlq1cTCGpkrh9g/ZrWqIZlMI4AbQ0V\nsBiE2Li2jbeccRRcIlx55+OYWQjGakiCMELLJbgO5e73IIxqXe9Fn29bl0cXFIrsiZlkCA0CNnTO\nXjwzrzzxMLzoOVsyn130bw9oU5JnFny8/MTD8JYzjsJNDz2NW3ft0x53bjEY6qJG/N7PfO5WnHfy\nNnzs2vsq6cBBEOGEbevxljOOyrz/6L4F3PLjZ8AYAxHlZGuAyUnJ22C7IWb6gbapkGiDasoVp4Zk\n+QZgMQhrTSLjQBBFyXc0gRCYm3T2z2zf117LrEy3l2w7TgQRg+c68BzKZW0FYb3rLbatK+y36GcL\n34DYI1ksvxbieRjmcyrGLlbfuTEp9ycIIxwYhAntw7fRGJv4vbkh1sbkCzmrK8/V2hCB6W4LfsiS\ne5geW46RpB7JOGENiSFmFnytzpEwCMaGJF4RBkPySBYLeOJJQX7QTSBWq5M0JIwxzCwE2nFnGwdN\npt/DIIjQcvQeSRAyDIIIjJktTMR3rPsddJMbl5IvnxTFb2aYirTimRH3IzOmbn5Mc4vC8HjJ/zML\nfu6azY7gWdQVclZ5aLIQowxVlibtEaOLkVhD0kjM9P0kuCVDprZMMFRqy6+3Gh0H/JpUi1idTTKN\ndDGIYopIZ0jCfOOgMY81iCK0Eo8kT23xcZo9B+LeLJXaksFX1xU0TfL7GN7EJs4pJtbMmKbyYxL3\nS/ZIgohhwc8+p2K/qgSCOtAVclZ6JH7+Wot95XFqqa0pS201FlHEMLcYaL2IoK5HstKprZDV8pKa\n4JEkKzxfQ235kaR4O5kivCBk8FyC6zhajwSoYUh84ZHUpLY0q2Sxui7zhlLqd5geCT/Wuo7GkGjq\nKFLD08r8L0+2wiuVtx8GdA3BZis9kihHIwJp7c7+eJxl1Jb1SBqI2cUAjAERy2sd+VG9FZe4+bp4\nS11w7rk5HgljDH6NGAljLHngJym1kazwKqit3oRkQQah5JEoCxDxHJkuKBJqq65H4ucnt+mu6ElS\nfG5h+Ibtkaxtu9o6iZ5mxS/OLSZiXVW+8Er59kOMkfhZj6RX4cVFEcMgLIiRKEZCl7W1ru2BaPzP\nqDUkBpBvikpJpTESQ2rLH6ZHEtXix0eNMGJgzHxS6/tR7es3CogVXhCxnNcpr8TTCWjM1FbISrK2\nYo/E0AtMqK0lxUgUastASn6wxJhMGWYWfG2gXYxJZQ8Sj0SitsRx5GOq2w8DahxDxHCKfrNpbUgJ\ntVUSI3EcQq8zfil5a0gMID9YeWqhrkcynBhJEEaJd9QUrySoOR75ujbBIwGQi4PJQeZuy0XHc8Y+\n1iDiVcqeq8/aEuM0QeqRDIHaMgjsph7JEKmtvq8NtMtjmpMKAJMYSRJsz497VM9intryCuNxgD7u\nIZAY7thICCo2b+DHL5MyUkNCROcQ0T1EdD8RvUfz+VFEdC0R3U5E1xPRdumz/0VEdxLRXUT0MYoT\n2OPt7iGiW+N/h4zyOwDZH4G6Yq2dtSWorWV6JPKD2BRDIoyj6ep4VKvAupDHoY493zhovKJ4jDH4\nISvN2gJqUFv+0jwEXdZWSvUVG4m66fEmmFkItIF2QB//yMVINLUW+zPbDzP9t55qstqJUkahR6K5\nLysmRkJELoCPAzgXwA4AbySiHcpmFwL4JGPsJAAfAPCheN8XAXgxgJMAPB/AaQBkDY1fYIztjP89\nOarvICDfFJWSCqJ6K7zEI1lmjCRrSJoRcJcnNRO6LbsKnBy1JU8cqlHONw4ar0y3MBxFWVt+VNcj\nWWLWliaTyITaShZaQ46RFHsk+fjHzIIPIh4/AMbskfj5YLt6vsz2QTG11W25aHtOsu+gYNtxP6PA\naD2S0wHczxh7kDE2APA5AK9RttkB4Nr49XXS5wxAF0AbQAdAC4BefGYMKI+R1CxIFDGSYLkeSWo8\nmlJLIq5FxMxUanWrxkkg45EoRjnXOGjMHokwzp7raLO26nqBaR3JEqgtTbCdH6vMkIzAI+mXxUg0\n8Y9+gF7HgxNXq6fKxZOIkWQzr/Lb5zXNZMh1MroYCTD+ZxQYrSHZBmCX9Pfu+D0ZtwG4IH59PoAe\nEW1mjN0Ablgei/9dxRi7S9rvH2Na639QgXoeEb2NiG4iopv27NmzrC8iF1OplFTdFdewsrbkiaMx\n1JY0yZmMSTzsW3udxsRI8h6JQm2NWaZbeBwtl7QeSW1qS8raqpOkMSgoSBTHKsJIYiQLQTIhq9AZ\nNzU43/FcdFtOxpiK1/xZHD61JeR3qjySfkmMhO+fZn0VGZ1JSMmP0pDoJnj1yX0XgDOJ6BZw6uoR\nAAERPQfA8QC2gxuflxDRz8T7/AJj7EQA/yX+9xbdyRljFzHGTmWMnbp169ZlfZEMtVUQ7DSt3B1W\nHUkzqS1pTJqaDBXiYd+2YWqiWVvyxCEbaJHQkPdIxjdWPxCGxNHGSPzadSRiIZMvyCvdT5O1ZZLF\nNmyPJIoYZks9knz8Q0eFqZNt9lkcbrDdcyhJVa6OkWTl+lXI8i5FNBg3NiuH2toN4Ajp7+0AHpU3\nYIw9yhh7LWPsZAB/FL+3H9w7uZExNscYmwNwBYAz4s8fif+fBfBZcAptpJAfyuL03/FmbWWoraZ4\nJGE9L0k87Ns2TDXII8lf13yMZIzUViSoLdJqbflLzNoC6nkJumB7y3Wwpu1WxEiGW9l+YBAgYnp5\nFKAg/qEJzk9PZfW2Zvo+2p6DLeuG6x3z2JKm8rxgoq+ktqSMLLHoaWs8kqIC6lFhlIbkewCOJaJj\niKgN4A0ALpM3IKItRCTG8F4AF8evfwzuqXhE1AL3Vu6K/94S79sC8EoAd4zwOwBQ0n9z1Ba/WXOL\nASKDuMCwtLYyHkljYiT1qa2O53A6oTExkrwx1GVtjat2RzxfLSf2SNRkjyRGUo/aAup5CYtBmJuw\nACH5UUJtDblOSBynKGsrKcjrV3kkXt7YdFuYnvKGqgvGq9Sz1ChQLKpYlImV7p+ltkR9UWabqXwK\n9KgxMkPCGAsA/CaAqwDcBeALjLE7iegDRPTqeLOzANxDRPcCOBTAB+P3LwXwAIAfgMdRbmOMfR08\n8H4VEd0O4FZwKuwTo/oOAmXBdrFiZAyZ5jVFSLO2lkltZWIkTaG2ZENiQm0FmJ5qYbrrGRviUWC2\nn3LuWY9E08wpVmAtaqo0bPih5JG4uqytmtRWECbf1VQhNox4CrK2SK5ESp4xlvw+hqVGWybYCEgF\neQptpVJhaq0FD+B7lYaxLtT6myTzqijY7uvpKoGeEmzXFy6K+zs+QzLSpgqMscsBXK689z7p9aXg\nRkPdLwTw65r3DwA4ZfgjLUdZ+q9sWGYWfKwv4G4FxOTkL5OOaiK1NQjreUl8pehheqoFxoC5QVA4\nQYwSM30/9oqCrIFWlFsBmZrwMdUefctd4XG0kqytrIGuTW35UfJdTamtgYbiEyibeOXfyrAC2Ikh\nKfmdqVlLM/38czXdbeHhp+Yzx+UeSStZ1DhD6EmiVU0uuWZldSRAPtheJqWyf8HPxBZGCVvZboCZ\nBZ4+COQpqSBkyWcmKxnxg19uQ6omFiQGdWMk8UqxKgA5aswsBNja432+dde17eapiXGNVUzGuqwt\nIUnDx2pObYnvWreItmjSKjqOyEzsdTws+GFikJaDhNoqWXDIKbJBGGFuURcjUbyWfuodm7ILJlj0\no3wMY6o4zqZmeamY7rYwCCL0/TAXf5G3AcabUm8NiQFm+j42rePdD1VKyg+j5DOTVVeqtTVEj6RG\n9s0oEUQ1qa1+yksDkytK5B4JbztbSW0lwdzxjFU8J56Tz9rya3qAAP9O4rvWlfUpolGKKBRhBMXv\nYxj0VuqRFJMp8qo96UWiy9qSYl2zC6l3LJ9nueBeg1owWJz5V1QbkuwrJROo8Zd0m/H/nqwhMcDM\ngo/Ncf9jlZLywyj5zMwjCZP9loNG1pHUnNhmVY9kAgH3frxS3rqu2CNRs7aA8Y1VrOpbXr5DYlCz\nbkdst0UsfGoKjRZ6JAWTrnge0t/H8ic2cd17JR5JT0rtFUaup9Sd9JRYV+qRDPdZ1EvLlHgkBfpZ\nArK8SyG1ZT2S5iGKGGYXA2xayycatZAwCFnymckqJqG2VqTWVv2srVGsAutALooEoI+RSD/qcUvJ\nJ9SWQ3BUj6RmLRFjvJvidLdVS3yySv9ppq9XsxXPeJ3fRxWKDIM6JrHd/oKYihzrEv+PwjvW9RYp\nowMrs7ZUj6RMbn6MvydrSCowN+C9SBKPRA22R1GtFdfQsrY0FMykkY2RlI9JNBLKrgLHT22JCSON\nkVRRW+OVkk+orVhrS85sk4tjTQy37GHVkdEopbamPIQRw7ymJ0neIxkOtbWm7aJVEEMQY1Ibpumo\nLXE84ZWKrK1hjRUoobYKJVKq0n/TcRd1UlzXGe8zClhDUgmxstkc0wE6j2Sj+KGYeCTDqiPRrJwn\nDdk4VgVWRSOh7Cpwch7J5rVtEGXHrctWGnewPZCC7WqMJJNubfAMyAahjrBfWbC9VzLxJoakRgyx\nCmWCjQLT3RZmFwOEUdr1UFeQKI4nG5v1Q17N66VliptbiXqdAuUnrJcWMjr9MwBwNSnQo4Y1JBUQ\nN2NTEiNJf7wiT77jOXEzGXNqa/nB9ggO8eyOxlBbNeg2OWi6rkbW27Ahp5N2PEdLGcqrPlWBddTw\npfRfNWuD+gsTAAAgAElEQVRLfobUPio6DKTVbi2PpCxGUiIlL4zepqF6JMUS8smYREFePyjxSFIK\nKzU2w/eOi9J/ReaVCp3hUfcFeOJCEbUFjF+40RqSCoiJZnOStZX+YOXUTB50LH/4GGPJD365MRLe\njtNFp+U0h9qKzKktOWjquQ7WdcYvfc3Hwc+5fspDx3O1GmZ6UbzxjFWWSFHVfzMxKYPMPfn71BH2\nK9N/UmMNMvIeyRAMiZFHko6pqO5E55H0uh7WaZSBlwO9/H6xF1dUZJjbdyEo3bY3Zil5a0gqICaa\nJNgu/XiTjBrXqezFDPAfvohJLrsfic/dWnXymyT8GlSLkNEWP3pVsmJckCuluUei0dqqQU0MG2Ue\nSbDkGIlbS3yytI6khOoTz8N0twXXoeF4JCWCjcmYMkYiABGSWq/cuPtB5hlIaKFhxkhy8vvFAf2i\n2hCBjueg7TpxsF2ftQVYj6RxSDySJNgueSRB2iuCZ4qU3zh5klp+PxL+wHU8pzkxkhoFibmudRNo\nD6qOo9NyCirbdcHScWdtCa2t/PMHmCVcyBRVHfHJsgBw2eparsofVrOlMgn5ZEwS3Taz4GOd1ItE\nQO5JInulAIzYBVNoqa1Sj0Qf9xAgoiR9WFfsmJxjzFLy1pBUQNzsTZqsLblXRJnmkIA8uS67H0nQ\nQGqrhtaWqpk0bI0jU8wsBGi7TmyUDamtMUrJB0nWVr6yvX7WlkRt1RCfLDKoQPnqWtYJG9YK2cwj\nkaitAiqs23J5CrRMf8XbmbALptDRT2VeXBW1BaTPX3mMZLjik1UwMiRE9CUieoWk1LtqIH4gwpDI\nK8Kke53jGE2E4se+pu0OoR9JqJ38Jgkxsa1pV49JPOTTySpwUjESLtZHRFpqyyHAU9VVux5mx+aR\nSFpbrj5ra03bXULWlrn4pFHWluZ6yNTvMFbIPGXcLGtLjEmkmGu3iz0PnXc8jCp8XT8bIPV8dBN9\nmXFIxi08kiAs7VvSRI/kbwC8CcB9RPTnRPS8EY6pUZjp+1jbdpObm6G2Qtkjqb5xIiC6tuMNpbKd\nx0ialLXFJ7a1Ha9yYlOzaSbnkaQTky5rq+O5uVTMcfLPZVpbYlGztuOZUVuZOpL6+nC6Ca7tOZhq\nuaXB9pbrDKXZ0oFByHuRGGZtzcRZW8XdFL3YI0m9Uv7+cKitwla4JSnTi35x3CPZf6qF/QvVWVtz\ng/EpahsZEsbYNYyxXwDwUwAeAnA1EX2HiH457guyYiGEBYkILZcytRK+wgHPVkihiwer1/GGUtne\n8dw4RtIQaiviK3jukVRRWwHanoNuvKLqlWg2jRKz/SDhyzueq8RI9Hy1mGjG0ZNErOrlnu3ivCID\ncF3HM6O2/NSz6ElppJX7lRQkAsXeZEJtOWQUQ6xClYS8QK8T9yRZ8LUS8um4W3GMJPVK+fGHQ20V\ndzAsTpku0s/K7N9t4ekDAzBW3rdkmOKTVTCmqohoM4BfAvBrAG4B8FFww3L1SEbWEMgcq+c4WWor\nynLAQgq9COLBWtvx4EfRsiaihNpqNYjaChk818xLUrlrQSeMuyeJzLmr8aZiCQoPgzAay3WXJ2NB\nsYlLJBYjaztmz4BakAik2XOl+/khiLhXpEORN5kWUzpDWeWrFFQRHId4Onnfj3vNFBiSWN5FpcuG\nlfhRRAnKmVf5fQyorSkPe2YX42MVGffxFs6axki+DODfAawB8CrG2KsZY59njP0WgHWjHOCkIRdA\ntVzKxDZEgZf4ofDti29cSm25YAy5JkV1kMnaaoghCcIILYfQNjEkC36GopjuthAx3kp1nDChtlSM\ns7o9EyOJDYnwUsT/a9ueYR1JtiARMKe2OiXV1kVUX5b6Xf4qPykcNOhZIwyX+pxltplqYTbO2upJ\nxsmEXTCBrp8NwDOviqTky1J60/G1sCC8yyKV4DELN5p6JH/FGNvBGPsQY+wx+QPG2KkjGFdjMLuY\nTjQt18nENoRHIn4oQLkMROKRtL3M/kuBKHRSA8SThB9GsUdiQG0pK8Vxa1hlxjElUVtK1lbdlNdh\nIwgZHOKyF8IjEQuQQbyoMaa2JPHFOsawskiuILU3S/22MD8IlxUbFGMtE2wU6HU97JsfYHYxKFQK\n7iUxkmwcxYRdMEEZJdgrkJIv0s+SIXtkZVlbwPik5E0NyfFEtEH8QUQbieidIxpToyBnfXhutmd2\nkprpOEYrAPFgierZ5fyoRL55x3OH0jBoGPAjhpZrVtuicteTam6V80iklb1IaFBRhxZaLoRxBiB5\nJPwZFM/fui43JFVUqaxmXMdwV62SizwSlfoFltf+1ZTaEts8sm+Bvy4Mtstey/CfxfJCziKPRP/M\nqfsKFMvNN9MjeStjbJ/4gzH2DIC3jmZIzYKc9dFynQKJFMeIkxQP1tqk2+IQqK1Ww6gtl2rESLKr\nQGC8hqTvh1gMIiVGUk1tlQkVDht+yJJueYlHEgpDkmbJAdV6Wxlqq45HUmBQBYpSTdWsLdPzFSEN\ntld7JNPdFh55JjYkhcF2HuvaM7uo946XuVAoV03WG18jasvEIxnzwszUkDgkEaRE5AJoj2ZIzUGS\ntz4lU1u6rC0yEnsTK0IhUrg8j6R5WVs82E5m1NZClnKYhJR8UsvSrUdtldUBDBtBFMGLg9xubFCC\nKJ+1xcdbZUjSFXId8ckqaktk3KkekVyV3+ss3/iKZ6OsqZXA9JSXZCyVBdsBntmUWdQMaaFQFCMR\n51hyQaL0fcp6uwPj+z2ZGpKrAHyBiH6WiF4C4BIAV45uWM2AyFsXnKynSFTIqZkmK66E2hKGZFkx\nkgYWJIYRp7YMvCSRcikwCSl5lSrRFSTW1ZcaNvyQwXMUj0SltoQhqaATF4MoI1FumkllQm0FEUsC\nwAJyVX5ZyqspZhZ8TMUGsAo6DyO3jUxnaV6PlNrS1NWIxmNVHknPgNpKFLXH9Huq9hE5/gDArwN4\nBwAC8E0Afz+qQTUFat563iNJg+0mUuh5amuZHknLgec4CT9elFUzLgQhQ8upjpEkjYS0HskYDYly\nfzseVxwIIwbXocLA5ziD7X4YoS08klzWVpbaqvICVUFA00yqqpRUWdtqTTudUrTU1jKu2Wy/WkI+\nGZMm5pHbJuOF6DySEVJbGo+kql97sq8BtZUoao/p92R0VxhjEXh1+9+MdjjNgrpi5em/usp2B57r\nYG3bLaU7Uo/EzexfF0EYxX1Q3IT2ELLykwQPDFdTW7qgaSqiNz5qa0aRaRE/4EEQYSouqtT9qJM6\ngDGMNZCC7apH4idZW/y+m1Bb8jNiKqNRLW2eGolnre8m72faLAzBizORkE/GJBmG9YUxkiKPZDir\n+XKPpIXFuCeJKMqtKvxM9pWprSVk040CpnUkxxLRpUT0QyJ6UPwb9eAmDTVv3XOdjNhiIBWLAdWF\nTGKVvjaJkSyN2hLcuKC2ADPRvlEjk7VVMp70uqY/dmGIJ+mRiKC2mACKVuJJHcA4PJKIpTESJWvL\nT6gtPn4TaivrkZiJT1ZlEhUZiSCK4DoUX69hxEiqBRuTMRl5JPpthtVorTxGko+zlRmezL6SV1Z6\nX8Yo5WMaI/lHcG8kAHA2gE8C+NSoBtUUyF38AG4w9MF2SaOngtryHEI3nvyXmrUly4ELvrgJUvJJ\n1lZFjGS2II1z3FLyuRhJSxiSKPm/LL1yLDGSIJKytvj/aoxkTVssJiqoLdWQGIpPVuk/FRkJHt/h\nxm9t24VDy42RVEvIJ2OSDUNR+q8mRgektNBykymqsraArERNWSdKGVMtN7muVZRj07K2phhj1wIg\nxtjDjLH3A3jJ6IbVDKjCgm3PUaitNP0XKNYcEhA/ZJmOWgrkBkXiQWpCUWIQB4Y7noswYoUxoIRS\nyrU/Ha9wo+pxJt5d/INe9MPCwG5vTFLygc4jiZ877gFSzgAWQf0+pivWgUFBIpA3Ejy+w88nvJLx\neSR8TL2Ol1y33DYFHgn/e/k9z8VvUvcM6eIw4v5VJRPIHl4V5Tgu/TpTQ9KPJeTvI6LfJKLzARwy\nwnE1AmqbTp61le9QJ37oJh5Jp+UmhmepwXbZBU4NyeQ9kkESIykfk7iu65XA6bil5Gf6PlouoRtP\nxKpRLlVXHcJEYwI/jAqztvwgzpIzpDdVQUDzrK2KYHuBRxKEqRFMz7e8OhLzGEkqCV+ErpQBpvWO\nh0VtFWRtAVk6MP1dV8c605T1Co+kYdTW74LrbP02gFMAvBnAL45qUE3BbJK3HlNbboFH4qQPY6kh\nibNmWko9QF3ILrO6ip4kgijKyHEXGhLF0xOY7rYwuzg+j2Q2Dt6KbDd53HJCgw7j4p/lVb3r5rO2\nPEcy3BX1RGoaryjI65vsV8LFy90GZfAamOz5lrpCZoxl5GyqIALsVXIqchsD9f1hFCTq+tnI55Of\nIdOsLSBPxxZt0xhqKy4+fB1jbI4xtpsx9suMsQsYYzca7HsOEd1DRPcT0Xs0nx9FRNcS0e1EdD0R\nbZc++19EdCcR3UVEHxMFkUR0ChH9ID5m8v4oMNP3saadehDtnCGJYySeJD89DmpLWumktEZDqC2X\nklVv0ZgSSkkbIxmjR6I0PZLHnSQ0lIjijSdrK13V57O2uEfSNaW2cjESswB4lf5Tx3PRbTk5qm8Q\npFX54nxLNb7zgxBhxIbqkfDPvYxXKr+/bI8kzpLTTVG6uhrTGAmQTxDRbzMc8UkTVI6YMRYCOKXu\nhB0boI8DOBfADgBvJKIdymYXAvgkY+wkAB8A8KF43xcBeDGAkwA8H8BpAM6M9/kbAG8DcGz875w6\n46oDHtxLH0Qv16Eu1doCUCmFLh4s4cEsOdguie81j9qSxlTgJc30/YznIjCsPhCmUGVa5HFX/ajH\nm7Wl19pKCkBNqS3FIJgWCZp17cuvfuWq/HSbpRnfOjpbQBpgN+mmKHul8vvLNyTF2W56j6QGtTXl\n8dYCZYZkSOKTJjAtSLwFwNeI6IsADog3GWNfLtnndAD3M8YeBAAi+hyA1wD4obTNDgC/F7++DsBX\nxaEBdMFlWAhAC8ATRHQYgGnG2A3xMT8J4DwAVxh+j1pQq695PxJ9QSKAjBS6TsZBPFjCgymLkfzD\nt3+EFxyzCc/ftl57HIA/cGJykSeRmx9+Gnc9Nos3n3GU8XcVOLAY4P2X3Ym5WF6i4zn4g3Ofh8PW\nT2W2u+jfHsCZzz0Exz2rl7wXxLpQ4odQ5HEJaW9d58H9Cz7e8embAQCHTnfxvlfugFMQLO37Id5/\n2Z3Yr3HfHYfw2y85NjM+ALj42z/C9x56GgBw2659mesrG+XKZk7dFgZKHYApGGP46LX34fyTt+Go\nzWtLt/UDLs0P6LK2mBKTSj3AB/bM4YofPIbfOPs5yXVWKSphRN/3tTuwfqqFjufgD19+PA6ZTmtB\noogZ1SjpqL5Aytri23j48dPzyf19ziHr8PsvOy6zz57ZRfz9tx/Eu192XGaSrCMhD3Cj2+t4lVTY\n9FRLa5yKvOPH9/fxqRsfwu//3HGFz6VAWZV6t+Wg5ZISI6nnkZgYd6BebGmpMI2RbALwFHim1qvi\nf6+s2GcbgF3S37vj92TcBuCC+PX5AHpEtDk2FNcBeCz+dxVj7K54/90VxwQAENHbiOgmIrppz549\nFUPVY/O6No49NJ2I2l62IDGIInhxnjwArIkLww4s6ikdESMRE0LRRBtFDB/8xg/x1Vse0R9HF2yX\neO5L/nMXLvzmPUbfUcUPH5vBF2/ejdt378fdj8/iq7c+iv+4/6nMNmHE8GeX343LbsuOLwgjhbMv\nztrSGdoXPXsLjju0hwf2zOGWH+/DP33noUTBVYd7Hp/F5763C7fv3o8H9sxl/n3j9sdw+Q8ey+3z\n19ffj+888BQe2DOHrb0Ofm7Hocln8sp+UPGjXtsW97r+au+ZeR9/cc19+IZmfCqCKEqo1ZxHktTt\n5ONkX7/tUVz4zXtzWUHy99lx+DROPnID9s4tpvf6gb2Z88/Hz9VUu3yqWNt2Mac894MwHTsAnH3c\nIThy0xo8sGcO33voGfzlv96fi89cd/eT+LtvPYj7npzLvC+MlImEvMDrTzsCL5Purw6vOPFZOP/k\n/BQiJOZVduHqHz6Oj1/3AB5+er7y/GXp40SEXreVWQQJQ6LSbDq89PhD8f+dekTpNodMd3Dcob1l\nd2M1gWll+y8v4dg6c61+o3cB+Csi+iUA/wbgEQABET0HwPEARMzkaiL6GQC6WUV7lRhjFwG4CABO\nPfXUJV3JPz3vxMzfnpMPtsuuu6gPKZJ1XwxCrGl7iQdTdIMPDAJErNjQyIVOnsYjmVnwlywtL479\nF2/YiSM3rcEL/uza3LGEIVPfH4gOiRVxG7X/g8ALn70ZV/7uzwAArrzjcbz90zeX0gvis794w06c\ndvSmzGfP/5OrcoFdLsIZ4Fd++hi859zn5Y4nj1umD3UQXshS4lzi2CaBZ32MhJ/TD2LD3covTMRq\nerbvJ4FnNY33kF4XX3nniwEAe+cWceqfXpMbU5phV76i7bRcDJT7HSiG5NwTD8O5Jx4GAPjUDQ/h\nf3ztTsz2g4xHJ+5p0ThMqS0A+ONXqkx6Hq8/7Ujt+9NdTgup7IIwzGYtiivqb5T20oMKL1jGS3cc\nipdWGMmzjjsEZx03nuRaI0NCRP8IzYTNGPuVkt12A5BN5nYAjyr7PwrgtfE51gG4gDG2n4jeBuBG\nxthc/NkVAM4AL4LcXnbMUULtR+KHURLvANL876IJdDGIsHGNnLVVXmdRtKJP8s3d9FgZQ9L3lxwz\n0acWZ79PUmehnINnbVElZ29SD2Ai5V1Gd+jiLYtBhEEYFdIddait5RSCin1MMmp8nUciZOTjz5KK\nfD/7DPBzBMDG+LwlVEtR5lXqCVQYEs9J6FABuQZGhZwyvLXXSc+34Gf+V8dhWpC4XMjquRlDsiBd\n1wpUyu8rdKBpZXsTYTrifwHwjfjftQCmAcyV7gF8D8CxRHQMEbUBvAHAZfIGRLQlrk8BgPcCuDh+\n/WMAZxKRR0Qt8ED7XXF3xlkiOiMO/v9XAF8z/A7LRlvpRxKEDC3pplcFvgdCaDH+cRVJpIiHtcgg\nJSuXgoLEmYWgtCCwDNrU4pxHIgr2FEMi9WwvG78JZ2uSUZQGYPOTiy71UZVEUSF/36of9XKkacQ+\nJgWNfsASD1Y8N7LWVsslOA6h5ZLyDMQTnjJRFU1sRZlXprEJnVDnIMh6JDKKZFXE+dX7XpTpNyoU\njy9/XYtQ3Vky+4zKjccONphSW1+S/yaiSwBcU7FPQES/CS5B7wK4mDF2JxF9AMBNjLHLAJwF4ENE\nxMCprd+Id78UPB7zA3BP6ErG2Nfjz94B4J8ATIEH2UcSaNfBc/MSKXIwsSrtVTxYwospEm1MDUkx\nRQbwH684lm41uhhEpVkdVccuWnWnBXt5TtyTK61LYiRVQdD1U/ofcuY4JYZBl3VTlfmTjjuszNpa\njqKA2MfEI5FrMTwlRiJ/prYTSD0S/j9jrPbEBshyNuX3SyfUGUSskO8v6pdR6JHUaLM7DBRJyQuD\nZiZ2WSUt4+Hxmb60vXkdSdOw1LtyLAA9uSiBMXY5gMuV994nvb4U3Gio+4XgsvW6Y94EnhI8dniO\ngzBiiWQ7XxFqPJJCSoo/WMKLKYqRJNRWoSFJJzkttSUZorWd/P5lkOMvrmalK58rR22FUSZrq6yy\n3dwjKaG2+j5chxKtqcz+Ux4e3dfPvLdfIxYpQ0ttFWRkmcqS6JB6JAbUVsiSrC1XydqSvRW1l0oy\n4cXXzw8ZGKuohNZkXhUVj6rQCXUGYQSvU9zmlo+zaMUf5N7vtpyxrdaLnr+6Hsm6gu8vzqGrbC+r\nDWkqTGMks8jGSB4H71GyqtCSKKm2R7k8+SpqKylIjCcGvyBGMpt4FMWeDT+fKwXb+bZRxBKuemmr\n5ax7rWucpYuRRBFDxBBrbRWv1nkgO6qkKNYVcPYyhIiftuCr28Ld/dnMe0VikQJtVzYkhtTWMmIk\nJsF2XwpYqx6JH0VY10qlMvQxkuyzVBX8Vbl/U0pJJ9Q5CFNDlztXQQ/3omD2bD8YeQqrjCIp+YR6\nM42RlGphqTESvhCrSituIkyprV71Visf4gfth1Ei4Jj1SCqoLT/KaG35QUWMpMiz8UMQccNGRGi7\n6Y9YZHyV7V8GdcJRV7ryNvL7vqQ7VmZQ1fa2RRB1AGWT7WxJ0F4bIykQixQgouT7VuX0j43aCvMF\niSJrS67T6LQUakuJkVR5WAC/Zk8fGGTeM6WUOp6bk2hRs7Yy5yqIgRUFs+sINg4DReMTasnGWVul\n8vse+j5PNW/HC4GDMdAOmPcjOZ+I1kt/byCi80Y3rGZC/KAT9VWl4KqM7uAcNae2eI8Gg6ytCs9G\n1ohKMoE0aqJ1oMYGdEFUXbBdLs5MYkUaQ1YnjbNKz2qmZJU63fUwp8hDqG0BdBDfN6X4JkdtMcbi\nrK1s+q9a2Z6MW+OVzirPUpXIX95DyMoEFUFLbUlV+Sp0BXnyeHXB9nFlbAGp4dRdD/7/8MQuZQbi\nYIyPAOZZW3/CGNsv/mCM7QPwJ6MZUnORUFvJilD1SIpjJEFM/Yht1La9MqqyttSgKacV8qvcpVJb\nriS9oK505ePK74sMsVZF1laVVyCjV6GwKyrkdZieSlUG0nNX8/3i+5pnbS3dI+n7Uen+PB6HXPqv\nqrUlxqnzSlPv1oDamspfb1UmqAji/Iylz/RAqspXIQryCj0STaxmnB5J0mhNuh6iDkkeZxlMkhuA\n7MLxYMzYAswNiW678S0PGgKZ2uL/ZzngsslFjT20HCrO2lLoiPyxstkgchxDJ7lQB4tBmAn2cdqs\nqI5EorZEt0iXx4Ac0p/fxCsQqPZIioP2umDpzEKAtueUSprUpraWESMByuMkwvNICxKzHrFcp8Gp\npbxXmqO2qrK2+n7GGKgyQUXoaAo05ap8/fmyMZkwYphd1McgxiHzkRufJoYhvp9RsL2yIVg2DmOi\nadZUmI76JiL6v0T0bCL6CSL6CICbRzmwJsJTCsL8MJteW0Z3JCvCeBvPdYobPy1UFCQqhU7yajRD\nbS0pRqIcWxNE1WVtJUrIsWSMLkjPx2eWBcS3KVdTnlkICrl7XYGdKtKog7iWVRPvcsQydbEMHdJr\nGnskah2JVKdR5JUmz5JBammv24IfMvSVoL2pR6J+N7UfiQp1op7TGMD0b3MJ+WFBFZnUXdcylIk2\niuMDkrEvaaTWdJiO+rcADAB8HsAXwKVKfqN0jxUI1SMJItUjKTEkygq35TrwC1SCZ/r1qC0eqBsS\ntaUE/PQxkjDZViBIYiTSxKbpc1GnsKxKgbXUI9HUAZisasXKXk5o0G5XUTNUhkyabolHknp5BTGS\nSE3/zXqlUy03M0mJ7YqQ1nZkJ0yTe6Xz0NRklNz5lPRXcd6plo5SmoRHklVHyIyvwiOp6mfDj59V\nX1Ybjx1MMM3aOgAg109ktUFtSBWEEVrSCjeVqiimttqJISH4JRIi8j75YynUlhTH0DXKqQMhdZ8c\n23Mxr8hQpx6JPmuL76fv215HfK+sMY8fRpgfhMVZWzpqqx+gZ5TGGuYSGnLbDYnaKvNI5LgToMva\nSrsnZujN+Dtv3zhVm9oSYzo0VgCe6ft49tZyhWL5uDK1pVK/ufMpBXlCwHD7xik8uPdAUq+14IcI\nIlYp0zJs9LotPDkrjy+9ro+WiIkC6XUoM9yJ1ywH21eyR0JEVxPRBunvjUR01eiG1UwkDaniH+Ug\n7lEukKaP6jySbK8BtbeJDJWOyB9L4zUktIactbW0YLt6bFWYcFBGbYkmYEWGZMGH5xCmDFZeZY15\nqtKIdXUARWKRMmRqq2zSLYsDVUFXga6D8FjFZOySUtkuFcRmn4F0Qs5RWwZZRFmPxCzILasCCKgd\nEnPnK/BItm+cQhgxzA+yz/T4qa0stSqP78AgLJUgMmlSpRZlroYYyZY4UwsAwBh7BqugZ7uKRLVX\n9kiUFVehIVEerJbSbVGGeGCL9LLUQqdsjCT9YS5FAVjogSXHbpWk/yp8OCBRWxrJDDG+6al8IyEd\nyhrzVKUR6+oATDJ/xMq+anWYxoHqG2udSq8OwmMVixUnNl4iRjKQnj/5PqUT3pqk0ZoYZ5lE+XQS\nV+JjEu1tTbxHldZljGWq8rXnU2IkM8mKf03me9SJqw0T+fGl1xUoT5QwqdtZ0+b9hFL6ceVnbUVE\ndKT4g4iORoF8+0pGQm1lYiTZS8hpJpOsLUcrkSL4YEGB6WTK1XzzTMaOtO9SV8sqtZWvbOffTzZ0\nwihmqC1tHYl5PUCRjAZQPbn0lEkxPbeJ+GBYqdwK6BMRTCAHVcs8ElFnJAuDeo4jaW0pWVtJjIR/\n58M3TCUp0CaCgKpHsuCbt7dVZXGCKLuw0J4vLshLPClpxS9/j6VIyA8DwmMSWWwyZSiPVwcTJQEi\nyng9q6GO5I8AfJuIPkVEnwLwLXC13lUFtSHVIIhyWSmV1FaStaVP/z0wCBExYOs6LpKlm4xz9JOU\nsTPbD0r3rUI+tVhX2Z4edxAqE4cjUy36GInphFAmJV8VtE/qAHIeSQW11XIxMKC2gJj2W6Kx3jDV\ngufkC/JkJEWe0qredQhhxBBFDGHEpBiJk5mQ17ZdbFqbxolMCxKBfHV5vWA7H0MgpYMXnk+RSRHn\n3aZM1OOWkE/H58WGOEsZblMMnQ4mMSl+jlYmjrWiqS3G2JUATgVwD3jm1u9D32RqRUNtSBVE2X4k\ngDm15RVkbYmHVfRoKMoAy3gNbpbaSvcdToykKP1X/l4JDZNZIeuytsyzb8qk5Msk5JP9pWB93w8x\nCKLKcwu5GZPAZ1GKcxUWgwjdlltZJ6ObjD2H98QRyQ3Cs5ELAkVcQzYMiSCgUfA3W11u5JEoqe9i\nfKXB9m7WkIj/RVtnUfGdxMMm4JEA6W9yts/rkMRCrdQjMYiRiHNkYyQHJ7VlKtr4awB+B7yR1K3g\nTQAc0EQAACAASURBVKZuAJd6XzVIJFJkraOcR+IWehHicwBou6SNf4iHs8wYqIVOMsUy0/dxSK+7\n9ECwGn9p5b+PPKZ04sin/x44oPEk+gGetb6be1+HIilv+b2ySU5OHzadjOSsraqcfp23ZgJhpIjK\n62QGYX4ydhxCGEWpkZG0thjjXoxIi+5lDEn1Crkb97dRpdyNChIVaiuN75Rnbcnnmen76HU8bFyT\nTYs1udejgEz1HY6ppA6p7LkUMDHc/BxeWtleUcDYZJiO+ncAnAbgYcbY2QBOBrC0RugHMVpJ1pYc\n7FRjJPrJReVM1ba9AmLC27KuwiPJxUjSDJfprreM1bIaf+HfR652lg2L+F6BMukVx0iW4pHoDFI1\nb84lP9TVtUHWVqy1VemRaBIRTCDiL1zbyjz9F4g9kojlvBVZlobXfniZnh9inNUTW0tDKdUpSIyf\nB7GwKPWAsh6nqFlRYzXi/o+rF4lA6pGkBm26mx+fDiZUojjHasra6jPG+gBARB3G2N0AjhvdsJoJ\ntUVuoMmTL46RZCuL1SZZAjlqqzBGUpy1NT3VKiwIrIKO2ooYMqnKGWpLrEBFsD1T15A//2zfrMAN\nSFesusl2th/AIWCtphdJsr/kkZgGbLNZW1UxkqVTWx3PzaxGdUgkUjQxEuGttCXDLY4tPBKV2mq5\nlNSiFEEO/taLkWSFOtWqfP25lIm676PX9XKqBDMLPjoV0jajQN5j4nVI0wWCjjLSmGhFjESSpVkN\nhmR3XEfyVQBXE9HXMMZe6U2BKpGiy5MvmlzSymJBbTla9V8jaksbEI8QRWkFcJFBq4Iua0u8L58/\n/V5i4uDXpO0VFyQOgggLfmgcNBVNgfTB9uo04uzq2rxl7CDk46yOkSyP2tJ1JJSRUFuexiNJCkBT\nw82PHSWLCXnlbMq/6z0SE60tJUaiVOXrz5UtyBP3VG37O27BxmR8OY+JU1tr2x4cqqC2TGMksdec\nFDCu8Mr28+OX7yei6wCsB3DlyEbVUAiPZBBGaZ58zpDoPQHV1fVc0vYjEZPm1gJqK4z4edU4BgDs\nW/ARMf5wLnm1rIm/iPfFxK4zKsnEJjwSTWpsVWMpFZ7rYF3H01IIZRLyAtnVNT/G+sqsLScea1D5\no+54TiLXXgeLAe+cVyUBk9TmSKt616U47VqNkaT3SdCbcgq0adX0dLeFffODeD+hQrAEaktDy+nO\nJZ9nph9g24ap5DM5e2zcGVtAPkY30/exbeMUHEcoF5tkbVVTWwt+mOiMrXSPJAFj7FuMscsYY4Pq\nrVcW0joSJqW7KtRWnD6qIm9IHG2HxJTaasf7KX3RNeJ74ph75xYBQPJIlkhtaY6tZmqlnRlFcDW7\nAu14+etQR0JeYLpASr5MQj7Zd6qVFOSZt4x1k+MbZW0tNUYiqK2SYHug1OYAaR2JoI5EzEPI8/T9\nKGn41XIdrIlToE2bJnGPJG3TO9VyjYQEc8F2qT9NEdSCPPmeqp7RJDySXBabVIekk9yXkf5Oq9N/\nAWDvHJ9OV40hWc3wksr2qDBPvqyORO7z0Xb1BYkzfR9TLRfrOvwBK8qYUqktANgzGxuSJEZSb5LT\nCc0VUVviByDGk6SjaiQ7ku9WIwtIQNezAhAZPuWTS6/rJQV5YsKuWl2La3lgYEBtFSRWVEEkNIjV\naFEtykCzqnfjrK2EOpI8QAB4Zn7AvVIx4cUBfVNBQLkHjImxFkiKYJUYiVcSI1EL8mQRTtWbHHfG\nFoDUEC/IBi02dBXepElBIpD+FsQi8GBN/7WGpAZS9V9WmCdf5AmoK0KvoB+JyLgpUhLWpXGK14kh\n6baWRG3phOZ0TaoWgyihGsTEkc8icuGHLJHzAFKuuY74XtGqXVyn0n2lOoWZvo+WS6USIXzc2Wy4\nqm2XHodych3yVASaVX1SR5JTElCegWRl79Wmtmb7QSyPYj6Buw6h5VKO6izL2uLj4xOy6Oooroka\n3xp3xpZAr8vbPat1SKrEvApTaksshsR9W+mV7RaQOiSGUZInn4+RFNeRZAxJQYdE8eNNg5f6plK6\nOIY8iSyF2io7djblN5I8kgKJlHg/ebWdZAHVoraKPZLKGIkUbBar2iqNL3nVXimRMoSsLT4+/YSk\nBtSBNGtLUKttJf1XpjfF/zN9n2uoGVFbHgYhr+w3lZAXkK+Hripfe744FjK7GICxNLCfjZFMhtpK\nxtH3c+nmqsS8ijqV7YDskRycU/LBOeoJIe1QF+W61wkU6S+p6aRtlwqztkTmCt+vgNoyipHUm+R0\nQnNaassPk4kqobZC/cSW7b1Rn9oqqv42mVzk9NIZw7RjnTdWtu2SUqz9NGuLj08/IQ00k7HI2qr2\nSLIre+OsLWlMIh3XFPLixUQihY+Pp0Cr6dni/bqe0bAhrl+6CMobOh2q+tmkx+fHSzwSS22tfKQe\nCcvJpgu0XZ4+qkqfq0FsryhGkhQU5j0BcRyggtqKDVHdGElZ/CVHbU1lM7iSwLCTndgykulLqFDW\ndUkMwggHBqGBR5LWAZhIyPNxm1NbRVL5VRDPQlVhmy7zSXgkubodxSvtJROeoLaqRSiBrBc3a5AZ\nJ6MtFaH6mqp87fniCVlNNe7F7/d9Hg8at4R8Oj4vXohkDZ1J1lZZP5v0+Aq1ZT2SlQ8iSmIbRVkp\nCaWj6eGRpbZIq+ybeiQF1JaGe02C7XPpJLKUQHCZkcpRW8IjERNHbDhdRymQU9q2ug5hTUkRoQo5\n80oglTsxi5HwSdGwr4ZS6Fm1bVAg9V8EOaFBp1Cc3Tbv9fKsrTTZQ67bAdJnIM0uEh6JaYyEj2n/\nQlAr2C7GoFKdZem/Ypyz/UDqL5NSckHEksZSk/ZIcuOb8jC3GBTe+zp1O0B632yMZJVANKQKCrJS\ndBMvkH+wuIx8sYSI5zpwHSqmtgpiJGvaLlquszRqqyxGUpW1FffGECswXYxHeFsmvUgEprutJPMq\nOY5hKq9cB2BSdyKPW31dtq1uQVAEOaGhTJQSkIUPDTySImpLWtnXmdiEl1BnApfVDIqoXxW9rpfE\nsDLjjg3Y7mcWMu+PG4nHpNQhietSVEdkarjXtl04ZKmtVYdWrJFV6JEUehLZB6vlcukROatJNBIS\nPyKhRJs9TnEcY8/sYvKAL4V2KYu/iM9EQeSa+AcgU1vyhKeltpZQD6ALSJtKd8h1AKar67pZW4Be\nxqYIsuZVlfifqM3JaG25Ikai1u0UUFuxFPozBwbGWVsA8ORsP6aUahiSVt4jKUv/5eNrYX4Q4ukD\ng8z5xf+7n5mP/54QtRXHavYrtKzab12FST8bIE6BnmpZamu1oeUJQ1KUtVWQtuurMZI0A0xAbSSk\n08vSeg3x66fnB8lkKQs5mqKU2oo/G0jbtDNUBstoQmmD7UuoB9AFpE2lO+Q6ANPVdV1qC9ALaxZB\nvsZiNVqk2RREEYiQ0cdKs7aUup1W+gwIrxRIr9/T8wPDGIniCdTySOQYSTb5ovB88T18ZJ/wPNKC\nxMw4JuiRhBHDE3Fv+dTTy8q7qKgjCT/dbeHpeVGQaD2SHIjoHCK6h4juJ6L3aD4/ioiuJaLbieh6\nItoev382Ed0q/esT0XnxZ/9ERD+SPts5yu+gQuTx61IzgdRT0MU2MtSW0rYXyK+09b1AdAFxflwm\nFaItLWurJNgeGyV5G9lY+TmPRBcjqa79UKFbtdfpmDfdbWHv3CL6fmS0fd2sLUCvh1YE+fqJ1Wgh\ntRWynOhh8vwpWVFiwpafASC9RoyZTVKpJ5Cd2E3Q8dy00ZmmKl97PsVgCBkeMVEvxaANE/L42jFl\nLL9f5E2aUlv8WB6EuLaNkSggIhfAxwGcC2AHgDcS0Q5lswsBfJIxdhKADwD4EAAwxq5jjO1kjO0E\n73kyD+Cb0n7vFp8zxm4d1XfQoRXXfxTlyYuHp6+pSFepLQCZOInK/Wvb3OqoLenhS41Q/UCwTmpc\nbdsrqxjLxipQdMdSg5qef3YJaZxq8yP5tZEhmfLS1W4N8UH+uoLa0sSPqqCqQJelkYq4kwxV/Vd4\ngZ7rJK/lyV++3iYTWzeWREkppZoeiRQz4+Myy1ra/cw81nW8xDCmE3g8jollbaXjmJ5K43tlLQ6A\nfN2YyTkAS23pcDqA+xljD8a6XJ8D8Bplmx0Aro1fX6f5HAB+HsAVjLH5kY20BlouZakt5caXVaSr\nBYlANlCrSojoigrLsraAdLJcSiC47NiJIZF6f2c48SjbdlhPbdVLJwXkGEl9aotv06pFjyyJ2lpC\njETsWyYlH4R5dWk1a0vnBWY9Ei/3eRXqXrPk+K0lUFvSil++nznPaGIeSeoZ6a5rIbVlmNwAqIbE\nUlsqtgHYJf29O35Pxm0ALohfnw+gR0SblW3eAOAS5b0PxnTYR4ioozs5Eb2NiG4iopv27BleDy7P\nzf6Q1Q5wKW+ej21ks7aykvRAXkJEp5eVytHrg8I9idoS5zWFrodCmj1WQG1JBYlaaisXbK9Jbeli\nJAt+3IvEwJBMtfD4jHkK6TipLTGmQo8kyve7UWMk8ufivsmTvyxHYypRPj3lSdesHrWVeKgF1K/u\nXADw+ExfGXf6ftsbfy+SZHzx9Xt8pp8pzjSitgxpKvk3YSKQ2USMctQ6n1atwHsXgDOJ6BYAZwJ4\nBECyPCOiwwCcCOAqaZ/3AngeeMfGTQD+QHdyxthFjLFTGWOnbt26dclfQgWvIykuSCyiO9QHS1YS\nFlCrZ0upLblKXvZIpGC7bhxlKNIHkoOo8jby+4FCwyTUllSgNm9QRKhCVWAVr3vdFpwK+Q2AX0vB\nP48sa2sZ17hM/M8P8h04RWW7SHrwtB6JvLJfmkeSXrOlUlv6hZbuXEA+tiPa/qrvjxtyjEm+Fuva\nHoiGS22ZNB5rKkZpSHYDOEL6ezuUZliMsUcZY69ljJ0M4I/i9/ZLm7wOwFcYY760z2OMYxHAP4JT\naGND23MyEimFWVvaOpJ81tZAFyPJBNvz1JYqvSAE84BssJ1vX2O1XNCMR46FyF5LtgCNZVI91fPX\niWvI8BQFVoCvAk2lO+QVuYlYJBElhrm6jkTvfZZB9frKpOSDiOViDK5DiCStrZaGTiz0SAwnNvna\n1pdIqVmQOKWn4eTPJhUfAVSjnI7VcQi9TrGUfK2sLSmuebBilIbkewCOJaJjiKgNTlFdJm9ARFuI\nSIzhvQAuVo7xRii0VuylgHjU6zwAd4xg7IVQPZKc1lYRtZXL2oo9EklvK20kJMdI8p5N281LL6Sc\ne0qLifOaIqVdsg+03Fsk65HI1FakndSSFsDKd6sDddVep1CuKPBcBjF2Y2prSTESA48kjPJZW0pB\nrK52R/6ebc/BVGy06k9sTq3JrdNyJQ+VwVFSl3UQKdDquPnfqVzKpNDTxEXSv4vvndogrvwc6e/9\nYMXIRs4YCwD8JjgtdReALzDG7iSiDxDRq+PNzgJwDxHdC+BQAB8U+xPR0eAezbeUQ3+GiH4A4AcA\ntgD401F9Bx24aq9UkJirbM9P4EEYIYxY1iPRxkgCdFvpj1fXHKqoQZEaaBXHKOp1ocNA4+0AyMit\nZAyJFGxX2w6r1JppNboO6qrdREI+2bdkIiiCfP3Lt6tvrFWp/l6XF+TpWgqoKdWAnLWVp47E4kE1\n1gndacrZK0V3phAeNO8emk8U0IGIkslaHbd4f1LFiADi+Ew+iQEQemAl1FbN630wG5KR3iHG2OUA\nLlfee5/0+lIAlxbs+xDywXkwxl4y3FHWQ9t1sOCH6YrQK9DaykiK5NNqRbaXr2RtZTI4NErCRQ2K\nUloju7qpR7voheYy1JactaUUoMkGiMulpMkBptXoOug8kiM3rTHbNz6f51CyMq9Cpya1VcdYJ9dP\norYATv1tWtvObBuEeWpLdEgMQt6lUr5XOmoL4NfviZnFWnUNfL9600PH42oNovK+KmNLPt9+jZqz\nrGA8SUx3W+j7i5rrWiwlvyRq6yDt1w7Yyvba8JT030KtLY0hydSROMKQZLO25IdVJ1NeVOiUTEzL\nytrSP/xy0F+WUcloKymrZyLKSLwsRUJeQKUQ6vSnkFfXphpfwoCMK2sL0Gf/+BHLrerlfiS6Xjjy\nMQXqcvBL90jSZz9Q0sGNzldAbU0y2A5IBi3n6RVn3NUqSLTU1uqD5ygFiQZaW/q0WkFtyR5JoGTZ\n6LO2dA9cWynk0hUEVqHQSHkF1FaJREq6XzZGsiRqS5GSNxVgBJa2uhbXsmpFPZSsrRIp+SCMcgWv\nPGsrwiDIT9SqVyogvrtpaqks+FgHaRM0TtVV6Wyl49MH1ZsQbAckg6bx9HTyNkKPru71PlhTfwFr\nSGqj7VGctVWhtSXLrmuyoZK2vVGFR6KNkWi8hoTHXQa1VSA0J9ezyOnHqkhfPhU69VjUjLQ6kD2S\nIIzilqz1YiT1Cut4dXdlN8Vlam3x8RVLyZfFSIIo/1lb8XIE5OC5CYomzirIhpVTW4YeyZTe8yjy\nVMaNIsPKY3f5BcBAucemx7ceySqCp6j/qqtCkT6qp7byWlt+IHskuhiJhtrSTfZS8Fb+u+4kV0lt\n+Qq15aey4TqjKgzQzEIQFxHW54FF0R5jLJHtNvdI6k9GwtuqghoHMoHaOa/MI/G1MRKRtZUvViyL\nkfDP601s9WMkErVlGGyXx5ePkSzNoA0bhR5Tt4XZxSCj4A3oNevKj5+t/ToYYQ1JTfAYiVSQqHHf\n1foP3YOVtO2V0n9nFVHDjufCD1nmQS2itjqei6l4JQ3kCwJNsBRqS2Qh8SydEmor9rbq9CIREFLo\nBwZh7aB9urquVw9h8qMmIq3XWAY1oUF8j1kdtaXxOlyHF+kNgjx1pHo5AuPM2gL4c+RramAKz1e0\n4m9A1hZQ4jHF455T6C1VT60Ka9seHDq4PZLJ3qGDEC1J68ghaKur1diG7sESne2EZ6PrTS0erEEQ\nYaqdrvY2aH7gHc/R6irJBs0PI9y6a1+ScrxxbQvPe9Z0ZpzFhiRLbXEl1NTQqaKN4jo8PtPHDQ88\nhR/tPbBkikLs96179iQTrunk0lsCPSIy0ky3le81Ywy37d6PhQG/7lNtFz+5fX1iOFSvr5TaCvJe\nh5icF/ywsDunWndRN71Ubd5kijRGEvGq/KHFSJrikeiTAb513x5sXZcqNYmujqYehuPwFOiDVfkX\nsIakNlpe6pEUVe3KlA4A9P18oZ+XZG1F8TacLtNVIi8GYWpI/BCdXl5e7JDpDg6fn9Lsm47j89/b\nhT/+arZ+8z//8GdxyHQ3PnYJtZXESMJkRS2nOuuUajetbePb9+/FGz9xIwDgtKM35o5tgkPj8f3G\nZ7+fe68Kbc/BIb0ODt8wVb1xjEOmO9g7p5Vwy0H1Pm988Onk+wpc8tYz8MJncwk51esTq9H9uqyt\nghgJwJ8p9bNDeh1s7XVyQdttG6fQdh2sN5yQt6zroO06OHyD2TUWyGZtsVxqfBG2bZxCx3Ny6c/b\n4nt2+HrzezcKbNs4hTVtN3f9xDP425fcot1v01pzA7htw1TGGB1ssIakJuQYSaEhUWIbuh7jadYW\n9w4ERy4/rHop9kC7QvujV+zI1DPoAsFPzvRBBHzm116A7z/8DC785r14cnYxNSRBiI3Kj1n9PnJB\nZIbK0GTpfPQNO3HvE3PJ3885ZF3u2CY487lb8ZV3viiR5l/X8fD8bdMVe6X4l9/66Vqr2j98+fHG\ntSGqsKZYjX7k9T8JAPi9z9+WvAfkExrEalRHbQlNMRleYkjyMYhf+y8/gdedegRUvPz5h2HnERuw\nYU3+3uqwYU0b//quM3FYzQm86nkownk7D8cLn705911POWoj/v2/n40jDGuGRoXXnXoEzj7ukJxw\n5E8/Zwu++hsvTrxPGd2Wg5/cvsH4HJ/61dMnJkw5DFhDUhMtN21sVcQBq3SHLvW1nWRtKemxOnrK\nLw7IC6zreIC0oNEFgmf6AXodDy969hZQrKkpB3lNqa2OIrnBg6t5w7p5XQcvHMIqy3EIJx+5NG8G\nQGIoTaFeyzIU3euffs7W3HuAPqGhSEpep5YsPBIdtdVtudrJyHEI2zfWm4zrbg9Iz4Ov91CL4LlO\n4n2omLQRAXiGpc6jdRzCziPMjUUZNh/E3ghgDUlttGIZ+VKPRAnA6lJfxWrSl4LRAJQYSVa3K4wY\nZg1TX3WBYLmQL+mnIHHzpgWJOY/Ej+BH5hPHSoJKbQmDIMt9yEZCl9Cgk5Lv+yEGQZRbNHgStbVm\nCRlwo4Ss7xbUqKOwOPhh73RNeEmHxHyxmIBaka5LfU2orTgjS0zova4uYM4ncZEdYi4+6OYMmpqb\nn/FICoTmOp4TB9SjjNeSThyhVs5jNUBnrDuek3gHHc/ReCQaQ6JQW0V1N66TPhNVyrrjRj5rq1nj\nsxgd7J2uiZa0Iiz6ofBCPLWhUzb1VZVI0U0c8kRdtE0ZcqtlSexQ15inSGhOXmnKAXnxf9/nwVVT\nTnwlQU5EAPJFpaq8iy6hQSclr/amERAeycIgH2yfNGShUJ61tfoWFqsVzXoSDwIIsUX+Qy7xSJRV\nqqps2lIkUnRxFLWV6/6aUuxqIFj2SHqdfGOeMmpLfC4XRIoVqCgSXI1UhppYocrcqPIuuoLSXi2P\nJF7IBGHjPEDZg9bVwFisXNg7XRNiRThfsiLU8eYqHSUmBJH+q+PWcz09akqx6wLBYmJyHMI6pTFP\nWUGi+DxDbcX/H4gNSVU3vJUIXTys1CMporaUGEmS6ad6JG5x+u+kYanO1YtmPYkHAcSPd8EvXhG2\nlTqSWU0jJiLe1dBPYiQpty6Qo7YW8mnEZagyaDI3L4TmynS8Fv0o47WI7C3hkaxGTrytM9bqNTbI\n2jowCBUBT/2iwZXSf5uW3CAyERf9CIOSOiuLlQd7p2siMSSlHok6uegzrVquk1Jb/bw0evLDXKJH\nImt+hRHLiR1yGWxuBBKhOa2Ol0Rt+fmsrYTaatjENg6oiRVqnc/0VFYhdtEPcxSguJ+zmb70empL\n9vqaFpPyXAeuQ1I6+Op7HlYrmvUkHgQQXsi8HxRKQOQ9AX3th2jbC+S5dSCvl5XWmtQItvvFGV9y\nY54yoTmZ2hoEUTIRtlVqaxWuQLXUlhojqaK2pjSGZEGfoedKz1wTV/zi2Vc7ZlqsbNg7XRNilbUw\nKClIbBXXb2SP5Ugxkvw2ql7WTD8AEQ+Um0BuPKVb4cqNeXRdHAXaUqwmQ20pHsnqjJGk3idjLPY+\n1WscgDG+YNBSW0JvS+kC2XIpafMqIF/jJq74hWEd2KytVQVrSGpC0AkLg6A4/Tfutc4Yr704MAi1\nHgmnttIYibqNGmyf7ftY1/G0QpH6caQGbX/Cucur5ZR2kVvo6r6P2CabtZWNkaz2rK3FgMcG5ISJ\nXtfDIK6/4dvks7Z0qdjieVDVkl2Z2mqkIeHp0IGtI1lVsHe6JgSdMO+HhTEB2QDodLYERNteIA6E\n5zySrF4Wp7/qNWjKt7qVV8ue5JGYUVsZra2WmrW1+h6njuckCsi6ALncSjdNaNDHSLIeiV5TLeuR\nNO96C8Oqk8yxWLmwd7omBJ3AWPHEKRuSsgB5y3WSrK1ZhVsX55L1snT0VxnkQLCOc5/utjA3CBBF\nLNNnJHecliG11cAV8qghF+EV0YcAv3dFnfN0cjXcI8kvPtymGxLP4UrWq1QyZ7WieU9iwyG768Ux\nklQjq6wRk+fwtr06bh3I62UVTS5FUBtLAcjRLowBs4tB6pFoRP/ExLcwCDEIU49EZJXNLfJ9V+PE\nIXtr+zXV6OL1/oWg0OvTdUksWjTIz1wTY1Idz8W8H5YutCxWHuydrgl5smyXFCQCPKaQeiT69F8/\n5s8HYV6gjx9Lpqf0dEcRMvtqMr5kbl7XV179PsLzEB6KMHSC2mriCnnUkL21Ko+kqHPeunasMqCJ\nkahwqPkeSfI8GPYjsTj40bwnseFomXgkMrVVkrLbitv2zpRIn8ipxEWTSxHkQLAu40vm5kuprfg9\n0TNDpmbkiWM1rkDlRISqGElRQoPjEHqdrJT8TF9fe+Rl0n+bN1F3WpIhWYXPw2qFvdM1kSkIK8na\nAmJqq0Ro0Ysl6cu2kfWydP0pyiACwVEcCFYzvmRuPqVddJXtbnz+IDmu/JlIKGjixDZqyNTWjCax\nIrnG/WJqi2/XMvJIXIPnb5LoeOnzsBpjZqsVzXsSGw7ZIymktqQWtDp5+PRY3CPRcevJsTwXi2GE\nKK5MV7vIlSEJBIeRtihS65FoK9v5e2KiyxgSz8GBwSqmtnTeZ5FHUuL1yXI1QtNM98w0P0ayup+H\n1Qp7p2siQ22V9CMBRPqvDyLOg+uO5YcVHklcnT67GIAxvbEpQiZWownmr58ym+Q8h+BQGgyWA/IZ\namsVrkDldsgzfR9tRS+t23LR9hzFWOe9PllKPk0ZL/dImli3k42Zrb7nYbWieU9iw5FZEVZSW1HS\n3lZXRMiztvT1B+mxnDj7q548CpAVfdSlF6ceSSAZkvwkx4PqbjLRZT0SN5F5WY0rUJnamtWoPANp\n4WcptSV5JGXPQ5O1toDs89DE8VmMBiO900R0DhHdQ0T3E9F7NJ8fRUTXEtHtRHQ9EW2P3z+biG6V\n/vWJ6Lz4s2OI6LtEdB8RfZ6I2qP8DiraGWqrwiPxw0J5FED2SIqLFkXmVV3BRrEvkBo0dRzrhDTH\ngp/Um+ioLfF+4pFkYiTN1n4aNVRqS3cPReFnKbUliTuWPQ+Nr2yXn4cGekwWo8HI7jQRuQA+DuBc\nADsAvJGIdiibXQjgk4yxkwB8AMCHAIAxdh1jbCdjbCeAlwCYB/DNeJ8PA/gIY+xYAM8A+NVRfQcd\nTDySrpISWjT5J4akzCOJdbvqSsgDSiBYE7x1k2yh8klOvJ/GSLLUlkATOftRI5O11dfHsHjjqqBU\nhkaWmy/3SKpjdJOE/DxYra3Vg1E+iacDuJ8x9iBjbADgcwBeo2yzA8C18evrNJ8DwM8DuIIx2Pcj\nnAAAEDlJREFUNk9ceOglAC6NP/tnAOcNfeQlkH/Ixem/kidQICEv9g8ipuXW02Px6vSleSR8rP24\nnkW/Wm7FWVuxaGMJXZdkbUmrTnlSXJUeSUs11ppr3BUeSbHX1+t6mF0MuNRKScys8R6J9Dw0MavM\nYjQY5Z3eBmCX9Pfu+D0ZtwG4IH59PoAeEW1WtnkDgEvi15sB7GOM/b/2zj3Wsquu45/ved7p3HkI\nnQE6rUxnOrSUKm2dmEotHR5iq4QSBBFBJ0TSGCACQiw1PiIJf5j4jgQhtFJig2BtpTHEV22q/EHp\ntEUFKtpUlGkrncF2OlPuzH3Mzz/2Xufse2a/zmvOvmf/Pslkzt53n33WOr991m/9Huu3QsJ92j0B\nkHSjpEOSDh05cmTELpxJMoCYV0Ye+um/eRZJFCPJrqEVCkCGWeq2oWIkYU/1tWgvktTZcrBIon1G\nBosEJvuUlbXV70/1BrZpM1gOJ23wD7skFrm2ICr3n1VCHjZCjKR4ouXMH9N8EtOeIhs4/hBwraSH\ngWuBx4HeqixJLwJ+APjbIe4ZnTT7pJntN7P9O3bsGLbtmSRn3dl7tq9fpJYdI1E/NTfDagllTp5N\n2U+kiPCjPnpiOcr4yhrk4sVyWW4tiGbRq3FdsHWurXa9Z6BnWJ8Zwfak1Zfu2uqXku9bJCkxkmRl\nhQquHE9aW1V0vTnTobzDfXgOAxckjs8HnkheYGZPAG8CkLQI/JSZHUtc8tPAXWYWVmodBbZLasVW\nyRn3nDalsrbWxUiyrY1WI9ohMW/FelidHqyBxRHSf4+cOAWkpw5vXWjz+DNLUTHGFNda/17pcZHa\nWyS9bYjXctyHsdWXk9AQlPyxpRWeXVqh1RCbUuRRfYskMbHwGEltmOaT+ACwL86y6hC5qO5OXiDp\nXEmhDTcDtw7c42303VpYtDvQvURxE4CDwBem0PZM2iVKVISZ2PeWV8/Y3jZJqxmn/+bU0Ar7Ozx7\ncoUt3dY6H3kR4Ud95HisSFItkr7/PtciycjUWh9sr97ANm16izVPrrK8ml4vbetCO64OfGb6dPKa\n6D4rPRdZmpux+jGSpGurfs9DXZmapGOL4b1EbqlHgM+b2dclfUTSG+LLDgDflPQfwAuAj4b3S9pN\nZNHcN3Drm4BflvQoUczklmn1IY1GQ70fc1ZwudEQnWaDoyeWgWx3VKfZYHntNMdzqvr2XFspCwqL\nCAN+UCRpK6XD+oW0LWAH29F/3Ux9XUeLJEwa8pV1e901aS6fZLmatG2XA5XP2nLXVi2ZpmsLM/si\n8MWBc7+ReH0H/Qyswfd+i5RAupk9RpQRNjNaDbFWsANct9XIHVxgfdZWnkWyvHaaY0vLqYogj55r\nK7Qjdbbc4sSpVU4ur6X67pPtGLwv9AeOVkOZgfp5JlRA7n/H6VlbEMkhK6EhzSJJI2mQVnHGvz5r\nq37PQ12p3pO4AQiWSF6efLfd6MUmshRAq9Fg7bRxbGkl85owUB89sTxUoB0Srq24HWkZX1s3tTGD\n7z63nLkYMdmO6L5nvq7zoNFt9WWda5GcOJVp9SVL+ufFzCT1Yg9VjEHUPWZWV1yRjED4geStm+i2\nmhzNsQSgXytpZc1y0n/7VsUwixEhoYRyLZK+26WMa6szMKMOyqqOa0gC3Xa+rMO5o8dPZSY0bOnG\ne5KcXI0XNmbLOrhWq1lrq97riuqKS3oEgkshbxa+fpaaZZEkS7pnu7Ygms0Ob5Gsz9pKy/gKbYtm\ny8WurUFlE47rPGgkZb0tRdbb1n3H2XG1xW6U+HA8Z+0RUG2LJGG5VtH15kwHl/QItAuC7RDNFsMe\n3Znpv4n35wXbISpJP2ywPQQ7l1dPZ2Z8hbYtlwy2DyqbZIykrnQTss4qkQLF33Eo7phXDQEoTPaY\nJV4ipZ5U70ncALRLzMKTP6gsBZAs+phpkbSLlU0WIRCcd//k+dx1JO2gSAYtEndtdRLKNc+1BemL\nEXvXbWrz3edOsbSylm+RlLCIZ0VnXYykvs9E3XBJj0DPtZDr2ooGjMHtbdfdZ51Fkp0i3LtmSIsE\n+j/sLJ978nPz0jU7zXTXVqenVKs3qJ0tuonvYCElYWGh3eh9P3lxja0LLR5/eil6nSPralsknrVV\nR6r3JG4A+llbxVlOg9vbJkm6g9J869F98me7RYQfdrZF0v/cMllbgwNhP2urvo9Sz+pbSF9EKKkn\nu1zX1qY2h3uKJNv6DM9NFfdE77pFUktc0iMQZlpFwXbIH/yTg3JR1hYMV0K+bDsWE9ZSqRjJgPvL\ng+397yTPigh/y3Mfbl1osxSXUcl7bpolLOJZUfdtBepKfX/9Y9CzSArSfyF/cEmuUs7O2ipWNnkE\nSyK7TEujp0xGy9oKMZL6Dhp9ZZ2t6MPf8i2SVuJ1cdZWFZV3UJQSQ5XzcTY21XsSNwDBpZA3eJYZ\nXMKMstNs5GwolXBtjRAj6Sm0HCVUZpDrZ20NKBLP2ipMaEj+rShrK+31IP0YSfW+856F2sjeksCZ\nP1yRjEDftVUcU8gbXMJAsHVTK3sfkPaYFskwg1yJGMkZ6b8eIymprNvrrk29JiGj/BhJg2ZFS9K0\nGqKharrdnOlR31//GPRdW8VZW3mDS7hP3jWTi5HkuV2KB7mea6ud7tqqc4G+Ivdh8m95yjqZWVdk\nkVTRGoGQct6spNvNmR5TLdo4r/RKpORlbbWKB5cQI9mSYy0kB/fFjDTiPHqB4JyBacs4ri2vtVUq\nsaJU1lZ8TbMhzulkK/VWU5XM2Ap0241auzrriCuSEQgKoEzWVtpK50DPtZVjLYQZ7OZOcyT3URmF\nVsZ/X7yyvboD27Qpk1jR/47zXFuRjLYsZLs6IVI0VVbc3VYDpW5m6swrrkhGoNTK9p4lkP0VD+Pa\nGiXQvu79ZYLtuSvb87O2qrjt69miP2nIlnUZqy/IqCgW1mqo0q6jbquJpe+A7cwprkhGoEytrTIK\noJUItmfRKaFs8hhutlxmHUmGa6vOFkl7CNdWTowklPkvioU1K69Iou0RnPpQ3aexwrSaKsyTL2MJ\nlLFIQr2sUQLtMOQgN4pry2MkCWVdItie59oqbZE0Kv19d9vVbp8zedwiGYF2s1E4IywzuPQUSYHb\nqttqjGGRDJFRlJe1leHakkSn1ah31taEgu2hzH+RrKtvkTQxN0hqhSuSEWg3G4UlsstYAiGzpWgL\n3W67OfQ2u733xsohL+MrtDGvoGBW1lY4V+cZaJnEijBZyPuOmw2xpdsqlHWroUpnRXVbDVbdtVUr\nXJGMwJuu3MWeHZtzr7lm3w5+8dq9XPLCLZnX7Nq+ife+6iJed+kLc+/1wR97CXt3Lo7U1hsuP49z\nFzu5GV9X7zuXG1+5h8t2bc285vmbO3zgtS/hx192Zltvuu4SLtu1baT2zQMHLt7Juw/s5aIcGe3d\nsci7D+zlVRfvzL3XTddfwqXnZcsB4OArdvPM0spIbT0bvOuaCzm1cnrWzXDOIrIa2KD79++3Q4cO\nzboZjuM4GwpJD5rZ/qLrqutodRzHcTYErkgcx3GcsXBF4jiO44yFKxLHcRxnLFyROI7jOGPhisRx\nHMcZC1ckjuM4zli4InEcx3HGohYLEiUdAf57xLefCxydYHM2CnXsdx37DPXst/e5HC82sx1FF9VC\nkYyDpENlVnbOG3Xsdx37DPXst/d5srhry3EcxxkLVySO4zjOWLgiKeaTs27AjKhjv+vYZ6hnv73P\nE8RjJI7jOM5YuEXiOI7jjIUrEsdxHGcsXJHkIOk6Sd+U9KikD8+6PdNA0gWS7pX0iKSvS3pffP55\nkv5e0n/G/3/frNs6aSQ1JT0s6a/j4wsl3R/3+XOSOrNu46SRtF3SHZL+PZb5j8y7rCV9IH62vybp\ns5IW5lHWkm6V9JSkryXOpcpWEX8Uj23/KunKcT7bFUkGkprAx4DrgUuBt0m6dLatmgqrwAfN7KXA\nVcB74n5+GLjHzPYB98TH88b7gEcSx78N/H7c56eBX5hJq6bLHwJ/Y2aXAC8n6v/cylrSLuCXgP1m\ndhnQBH6G+ZT1p4HrBs5lyfZ6YF/870bg4+N8sCuSbH4YeNTMHjOzZeDPgRtm3KaJY2ZPmtlD8evj\nRAPLLqK+3hZfdhvwxtm0cDpIOh/4SeBT8bGAVwN3xJfMY5+3Aq8EbgEws2Uze4Y5lzXQAjZJagHn\nAE8yh7I2s38C/m/gdJZsbwA+YxFfBrZLetGon+2KJJtdwLcTx4fjc3OLpN3AFcD9wAvM7EmIlA2w\nc3Ytmwp/APwKcDo+fj7wjJmtxsfzKO89wBHgT2OX3qckbWaOZW1mjwO/A/wPkQI5BjzI/Ms6kCXb\niY5vrkiyUcq5uc2VlrQI/CXwfjN7dtbtmSaSXg88ZWYPJk+nXDpv8m4BVwIfN7MrgOeYIzdWGnFM\n4AbgQuA8YDORW2eQeZN1ERN93l2RZHMYuCBxfD7wxIzaMlUktYmUyO1mdmd8+jvB1I3/f2pW7ZsC\nVwNvkPQtIpflq4kslO2x+wPmU96HgcNmdn98fAeRYplnWb8W+C8zO2JmK8CdwCuYf1kHsmQ70fHN\nFUk2DwD74uyODlGA7u4Zt2nixLGBW4BHzOz3En+6GzgYvz4IfOFst21amNnNZna+me0mkus/mtnb\ngXuBN8eXzVWfAczsf4FvS7o4PvUa4BvMsayJXFpXSTonftZDn+da1gmyZHs38PNx9tZVwLHgAhsF\nX9meg6SfIJqpNoFbzeyjM27SxJH0o8A/A/9GP17wq0Rxks8D30/0Y3yLmQ0G8jY8kg4AHzKz10va\nQ2ShPA94GHiHmZ2aZfsmjaTLiRIMOsBjwDuJJpRzK2tJvwW8lShD8WHgXUTxgLmStaTPAgeIysV/\nB/hN4K9IkW2sVP+YKMvre8A7zezQyJ/tisRxHMcZB3dtOY7jOGPhisRxHMcZC1ckjuM4zli4InEc\nx3HGwhWJ4ziOMxauSByn4kg6ECoUO04VcUXiOI7jjIUrEseZEJLeIekrkr4q6RPxficnJP2upIck\n3SNpR3zt5ZK+HO8FcVdin4iLJP2DpH+J37M3vv1iYh+R2+MFZY5TCVyROM4EkPRSotXTV5vZ5cAa\n8HaiIoEPmdmVwH1Eq40BPgPcZGY/SFRVIJy/HfiYmb2cqCZUKFtxBfB+or1x9hDVC3OcStAqvsRx\nnBK8Bvgh4IHYWNhEVCDvNPC5+Jo/A+6UtA3Ybmb3xedvA/5C0hZgl5ndBWBmJwHi+33FzA7Hx18F\ndgNfmn63HKcYVySOMxkE3GZmN687Kf36wHV5NYny3FXJOlBr+G/XqRDu2nKcyXAP8GZJO6G3V/aL\niX5jocrszwJfMrNjwNOSronP/xxwX7wPzGFJb4zv0ZV0zlntheOMgM9qHGcCmNk3JP0a8HeSGsAK\n8B6izaNeJulBot353hq/5SDwJ7GiCFV4IVIqn5D0kfgebzmL3XCckfDqv44zRSSdMLPFWbfDcaaJ\nu7Ycx3GcsXCLxHEcxxkLt0gcx3GcsXBF4jiO44yFKxLHcRxnLFyROI7jOGPhisRxHMcZi/8HpYYQ\nlCWYudsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2314caac88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22f8ddc518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "X_train,y_train = load_iris(return_X_y=True)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "#transform target to one hot vector\n",
    "import keras\n",
    "y_onehot = keras.utils.to_categorical(y_train)\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation=\"sigmoid\"))\n",
    "model.add(Dense(16, activation=\"sigmoid\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.1),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_onehot, epochs=100, batch_size=1, verbose=1)\n",
    "\n",
    "#C\n",
    "history = model.fit(X_train, y_onehot, epochs=100, batch_size=1, verbose=1)\n",
    "\n",
    "# Los datos que estan en el history \n",
    "print(history.history.keys())\n",
    "\n",
    "# Grafico para el accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Grafico para el Loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tercero\"></a>\n",
    "### 3. Verificación numérica del gradiente para una componente\n",
    "\n",
    "En esta sección deberá verificar numéricamente el gradiente para los parámetros del modelo (que en este caso son los pesos de la red), que hasta ahora a definido de manera analítica en su programa, por ejemplo la derivada de $x^2$ es $2x$. Ahora deberá verificar estos cálculos usando la definición de gradiente.\n",
    "\n",
    "$$ \\nabla_{w} Loss = \\lim_{\\epsilon \\rightarrow 0} \\frac{Loss(w+ \\epsilon)-Loss(w)}{\\epsilon} $$\n",
    "\n",
    "Debido a que el *forward propagation* es relativamente fácil de implementar, se puede confiar en que se realizó de manera correcta, por lo que el cómputo del error (*loss*) debería ser correcto. Esto significa que podemos verificar el gradiente o la derivada analítica del error $\\frac{\\partial Loss}{\\partial w}$ comprobando que el resultado obtenido es similar (dentro de una tolerancia numérica, por ejemplo $10^6$) al valor que obtenemos aplicando la fórmula anterior. Naturalmente interpretaremos $\\lim_{\\epsilon \\rightarrow 0}$ como un valor \"*suficientemente pequeño*\" de $\\epsilon$.\n",
    "\n",
    "\n",
    "> a) Para un peso escogido aleatoriamente entre la primera capa de la red (*input*) y la primera capa oculta, calcule el valor del gradiente de la función de error para ambas funciones utilizadas (ayúdese mediante las funciones de *backward pass* implementadas anteriormente), luego compare y verifique con el valor numérico del gradiente mediante el procedimiento explicado anteriormente.\n",
    "\n",
    "> b) Vuelva a verificar el valor del gradiente para otros dos pesos escodigos aleatoriamente en la primera operación de la red. Compare y concluya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "### 4. Implementar *momentum* como variante\n",
    "\n",
    "En esta sección deberá construir, sin usar librerı́as, excepto eventualmente *numpy* para implementar operaciones básicas de algebra lineal, una variante del programa definido anteriormente ([sección 1](#primero)) que entrene la red utilizando *momentum* clásico.\n",
    "\n",
    "$$ v^{(t+1)} \\leftarrow \\mu v^{(t)} - \\eta \\nabla_{w^{(t)}} Loss \\\\\n",
    "w^{(t+1)} \\leftarrow w^{(t)} + v^{(t+1)}\n",
    "$$\n",
    "\n",
    "> *Sutskever, I., Martens, J., Dahl, G., & Hinton, G. (2013, February). On the importance of initialization and momentum in deep learning. In International conference on machine learning (pp. 1139-1147).*\n",
    "\n",
    "\n",
    "Demuestre que su programa funciona en el mismo problema de clasificación presentado anteriormente, para esto, además deberá construir un gráfico de la función de error o pérdida (*loss*) *vs* el número de *epochs* y comentar/analizar la convergencia. ¿Es una mejora significativa? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
